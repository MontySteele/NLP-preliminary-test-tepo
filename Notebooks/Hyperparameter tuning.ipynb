{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "sent_token = nltk.sent_tokenize\n",
    "import csv  \n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "\n",
    "\n",
    "file_path_comments = r'~/Documents/Springboard/Springboard/Data/cleaned_comment_data.csv'\n",
    "\n",
    "#file_path_comments = r'/mnt/c/Users/msteele9/Documents/Springboard/Springboard/Data/cleaned_comment_data.csv'\n",
    "clean_comments = pd.read_csv(file_path_comments, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "X = clean_comments['commentBody']\n",
    "y = clean_comments['recommendations']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=random.seed(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "vectorizer = CountVectorizer(binary=False, stop_words=stopwords.words('english'), \n",
    "                             lowercase=True, min_df=1, max_df=0.9, max_features=5000)\n",
    "X_train_onehot = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\msteele9\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\msteele9\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\msteele9\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\msteele9\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\msteele9\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\msteele9\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\msteele9\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    " \n",
    "    model.add(Dense(units=500, activation='tanh', input_dim=len(vectorizer.get_feature_names())))\n",
    "\n",
    "    model.add(Dense(units=400, activation='relu'))\n",
    "\n",
    "    model.add(Dense(units=1, activation='relu'))\n",
    " \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# load dataset\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train_onehot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.223200 using {'batch_size': 100, 'epochs': 50}\n",
      "0.135125 (0.030969) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.129575 (0.003686) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.115975 (0.007959) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.164200 (0.005115) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.151850 (0.004913) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.139100 (0.007326) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.176700 (0.027827) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.176800 (0.008613) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.165225 (0.007088) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.216875 (0.004961) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.198200 (0.005164) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.186625 (0.007020) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.222425 (0.005550) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.220450 (0.004945) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.196425 (0.003424) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.221125 (0.004094) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.223200 (0.007873) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.201525 (0.008289) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [10, 20, 40, 60, 80, 100, 150, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1000, 1500, 2000, 2500, 3000]\n",
    "epochs = [10]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1)\n",
    "grid_result = grid.fit(X_train_onehot, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.224425 using {'batch_size': 100, 'epochs': 10}\n",
      "0.127000 (0.014607) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.147725 (0.021218) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.200725 (0.018156) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.209175 (0.009844) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.218400 (0.000219) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.224425 (0.007583) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.215850 (0.010240) with: {'batch_size': 150, 'epochs': 10}\n",
      "0.215800 (0.005768) with: {'batch_size': 200, 'epochs': 10}\n",
      "0.220325 (0.006775) with: {'batch_size': 250, 'epochs': 10}\n",
      "0.224275 (0.002925) with: {'batch_size': 300, 'epochs': 10}\n",
      "0.195625 (0.012638) with: {'batch_size': 400, 'epochs': 10}\n",
      "0.182475 (0.012463) with: {'batch_size': 500, 'epochs': 10}\n",
      "0.165750 (0.010133) with: {'batch_size': 600, 'epochs': 10}\n",
      "0.145975 (0.013723) with: {'batch_size': 700, 'epochs': 10}\n",
      "0.127475 (0.011878) with: {'batch_size': 800, 'epochs': 10}\n",
      "0.125925 (0.012141) with: {'batch_size': 900, 'epochs': 10}\n",
      "0.121225 (0.009107) with: {'batch_size': 1000, 'epochs': 10}\n",
      "0.091050 (0.012235) with: {'batch_size': 1500, 'epochs': 10}\n",
      "0.096600 (0.004166) with: {'batch_size': 2000, 'epochs': 10}\n",
      "0.186475 (0.061268) with: {'batch_size': 2500, 'epochs': 10}\n",
      "0.171375 (0.058036) with: {'batch_size': 3000, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
