{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In this notebook I attempt to fit my data using a neural network with the keras library. I import my cleaned data, perform a train-test split, make a simple neural network and build my model. Then I compare the predictions of my model with the actual results of my model to see if I can find issues in the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "sent_token = nltk.sent_tokenize\n",
    "import csv  \n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "\n",
    "\n",
    "file_path_comments = r'~/Documents/Springboard/Springboard/Data/cleaned_comment_data.csv'\n",
    "\n",
    "#file_path_comments = r'/mnt/c/Users/msteele9/Documents/Springboard/Springboard/Data/cleaned_comment_data.csv'\n",
    "clean_comments = pd.read_csv(file_path_comments, index_col = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.0\n",
       "1    1.0\n",
       "2    3.0\n",
       "3    7.0\n",
       "4    5.0\n",
       "Name: recommendations, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "X = clean_comments['commentBody']\n",
    "y = clean_comments['recommendations']\n",
    "y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this next cell, I convert my integer target, 'recommendations', to a category target. I create bins such as (-1 to 1), (1 to 5) and so on, placing my recommendation values in the correct bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "#set up bins\n",
    "bin = [-1, 1, 25, 1000000]\n",
    "label = [0, 1, 2]\n",
    "#use pd.cut function can attribute the values into its specific bins\n",
    "category = pd.cut(y, bin, labels=label)\n",
    "category = category.to_frame()\n",
    "category.columns = ['range']\n",
    "#concatenate age and its bin\n",
    "df_new = pd.concat([y,category],axis = 1)\n",
    "\n",
    "y_binary = to_categorical(df_new['range'])\n",
    "\n",
    "#df_new['range'].head(5)\n",
    "print(y_binary)\n",
    "y_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binary, test_size=0.2, random_state=random.seed(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "vectorizer = CountVectorizer(binary=False, stop_words=stopwords.words('english'), \n",
    "                             lowercase=True, min_df=1, max_df=0.9, max_features=5000)\n",
    "X_train_onehot = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My model's accuracy function will report back the % of samples for which it places the comment in the correct category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 200)               1000200   \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 400)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 3)                 1203      \n",
      "=================================================================\n",
      "Total params: 1,563,003\n",
      "Trainable params: 1,563,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "    \n",
    "model = Sequential()\n",
    " \n",
    "model.add(Dense(units=200, activation='relu', input_dim=len(vectorizer.get_feature_names())))\n",
    "model.add(Dense(units=400, activation='linear'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=400, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=400, activation='relu'))\n",
    "model.add(Dense(units=400, activation='relu'))\n",
    "model.add(Dense(units=3, activation='relu'))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/10\n",
      "32000/32000 [==============================] - 2s 60us/step - loss: 2.0692 - categorical_accuracy: 0.5487 - val_loss: 2.0032 - val_categorical_accuracy: 0.5732\n",
      "Epoch 2/10\n",
      "32000/32000 [==============================] - 1s 40us/step - loss: 2.0326 - categorical_accuracy: 0.6283 - val_loss: 2.0036 - val_categorical_accuracy: 0.5702\n",
      "Epoch 3/10\n",
      "32000/32000 [==============================] - 1s 39us/step - loss: 1.9072 - categorical_accuracy: 0.7320 - val_loss: 2.1074 - val_categorical_accuracy: 0.5526\n",
      "Epoch 4/10\n",
      "32000/32000 [==============================] - 1s 40us/step - loss: 1.7637 - categorical_accuracy: 0.8263 - val_loss: 2.3698 - val_categorical_accuracy: 0.5586\n",
      "Epoch 5/10\n",
      "32000/32000 [==============================] - 1s 40us/step - loss: 1.6863 - categorical_accuracy: 0.8661 - val_loss: 4.8611 - val_categorical_accuracy: 0.5481\n",
      "Epoch 6/10\n",
      "32000/32000 [==============================] - 1s 40us/step - loss: 1.6405 - categorical_accuracy: 0.8828 - val_loss: 4.1802 - val_categorical_accuracy: 0.5486\n",
      "Epoch 7/10\n",
      "32000/32000 [==============================] - 1s 40us/step - loss: 1.6079 - categorical_accuracy: 0.8938 - val_loss: 5.5175 - val_categorical_accuracy: 0.5407\n",
      "Epoch 8/10\n",
      "32000/32000 [==============================] - 1s 40us/step - loss: 1.6240 - categorical_accuracy: 0.8854 - val_loss: 5.4511 - val_categorical_accuracy: 0.5446\n",
      "Epoch 9/10\n",
      "32000/32000 [==============================] - 1s 41us/step - loss: 1.5664 - categorical_accuracy: 0.8968 - val_loss: 6.1461 - val_categorical_accuracy: 0.5489\n",
      "Epoch 10/10\n",
      "32000/32000 [==============================] - 1s 40us/step - loss: 1.5666 - categorical_accuracy: 0.8970 - val_loss: 6.1240 - val_categorical_accuracy: 0.5461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x187fe400ef0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_onehot, y_train, \n",
    "          epochs=10, batch_size=1000, verbose=1, \n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_onehot = vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 63us/step\n",
      "Accuracy: ['loss', 'categorical_accuracy'] 7.5276925567626956 0.4861\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_onehot, y_test, verbose=1)\n",
    "print(\"Accuracy:\", model.metrics_names, scores[0], scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now let's examine the predictions of my model. First I example five sample data points, and then I plot all of my data vs. their predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35958    As it turns out you can kill 400,000 civilians...\n",
       "32462    Two Faced<br/><br/>The plastic bag flies away....\n",
       "29993    One of Renee Fleming's best friends, the mezzo...\n",
       "34571    I know we are trying to see the dark side of g...\n",
       "21821    This article made me sick to my stomach. What ...\n",
       "Name: commentBody, dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1\n",
      " 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 0 1\n",
      " 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test_onehot)\n",
    "prediction_int = np.argmax(prediction[:100], axis=1)\n",
    "print(prediction_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 1 0 1 1 0 1 0 0 1 1 1 0 0 2 0 1 1 1 0 1 1 2 1 0 1 1 1 1 2 0 1 1 0 0\n",
      " 2 1 1 1 1 1 0 2 0 1 2 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 1 0\n",
      " 0 0 0 1 1 1 0 1 1 0 2 1 1 1 1 0 1 2 2 1 0 0 0 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "y_test_int = np.argmax(y_test[:100], axis=1)\n",
    "print(y_test_int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n",
      "0.73\n"
     ]
    }
   ],
   "source": [
    "#print(y_test_int.median())\n",
    "print(y_test_int.mean())\n",
    "print(prediction_int.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predictions')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_bins = 100\n",
    "\n",
    "# Generate a normal distribution, center at x=0 and y=5\n",
    "x = y_test_int\n",
    "y = prediction_int\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
    "\n",
    "\n",
    "# We can set the number of bins with the `bins` kwarg\n",
    "axs[0].hist(x, bins=n_bins)\n",
    "#axs[0].set_yscale('log')\n",
    "axs[0].set_title('Actual values')\n",
    "axs[1].hist(y, bins=n_bins)\n",
    "#axs[1].set_yscale('log')\n",
    "axs[1].set_title('Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I try to use Transfer Learning with spaCy embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#cwd = os.getcwd()  # Get the current working directory (cwd)\n",
    "GLOVE_PATH = r'C:\\Users\\msteele9\\Documents\\Springboard'\n",
    "os.chdir(GLOVE_PATH)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "print(cwd)\n",
    "\n",
    "files = os.listdir(cwd)  # Get all the files in that directory\n",
    "print(\"Files in %r: %s\" % (cwd, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word2idx = {word: idx for idx, word in enumerate(vectorizer.get_feature_names())}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "GLOVE_PATH = r'C:\\Users\\msteele9\\Documents\\Springboard/glove.twitter.27B.25d.txt'\n",
    "GLOVE_VECTOR_LENGHT = 25\n",
    " \n",
    "def read_glove_vectors(path, lenght):\n",
    "    embeddings = {}\n",
    "    with open(path, encoding=\"utf-8\") as glove_f:\n",
    "        for line in glove_f:\n",
    "            chunks = line.split()\n",
    "            #assert len(chunks) == lenght + 1\n",
    "            embeddings[chunks[0]] = np.array(chunks[1:], dtype='float32')\n",
    " \n",
    "    return embeddings\n",
    " \n",
    "GLOVE_INDEX = read_glove_vectors(GLOVE_PATH, GLOVE_VECTOR_LENGHT)\n",
    " \n",
    "# Init the embeddings layer with GloVe embeddings\n",
    "embeddings_index = np.zeros((len(vectorizer.get_feature_names()) + 1, GLOVE_VECTOR_LENGHT))\n",
    "for word, idx in word2idx.items():\n",
    "    try:\n",
    "        embedding = GLOVE_INDEX[word]\n",
    "        embeddings_index[idx] = embedding\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "from keras.layers import Dropout\n",
    "    \n",
    "model = Sequential()\n",
    " \n",
    "model.add(Embedding(len(vectorizer.get_feature_names()) + 1,\n",
    "                    GLOVE_VECTOR_LENGHT,  # Embedding size\n",
    "                    weights=[embeddings_index],\n",
    "                    #input_length=MAX_SEQ_LENGHT,\n",
    "                    trainable=False))\n",
    "model.add(LSTM(128))\n",
    "\n",
    "model.add(Dense(units=400, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='relu'))\n",
    " \n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer='adam', metrics=[myAccuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_onehot, y_train, \n",
    "          epochs=3, batch_size=128, verbose=1, \n",
    "          validation_data=(X_test_onehot, y_test))\n",
    " \n",
    "scores = model.evaluate(X_test_onehot, y_test, verbose=1)\n",
    "print(\"Accuracy:\", scores[1])  # 0.8296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
