{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>716</td>\n",
       "      <td>by stephen hiltner and susan lehman</td>\n",
       "      <td>article</td>\n",
       "      <td>finding an expansive view  of a forgotten peop...</td>\n",
       "      <td>photography new york times niger ferguson adam...</td>\n",
       "      <td>3</td>\n",
       "      <td>insider</td>\n",
       "      <td>2</td>\n",
       "      <td>20170401 001541</td>\n",
       "      <td>unknown</td>\n",
       "      <td>one of the largest photo displays in times his...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>news</td>\n",
       "      <td>httpswwwnytimescom20170331insidernigermigrants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def3237c459f24986d7c84</td>\n",
       "      <td>823</td>\n",
       "      <td>by gail collins</td>\n",
       "      <td>article</td>\n",
       "      <td>and now  the dreaded trump curse</td>\n",
       "      <td>united states politics and government trump do...</td>\n",
       "      <td>3</td>\n",
       "      <td>oped</td>\n",
       "      <td>23</td>\n",
       "      <td>20170401 002358</td>\n",
       "      <td>unknown</td>\n",
       "      <td>meet the gang from under the bus</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>oped</td>\n",
       "      <td>httpswwwnytimescom20170331opinionandnowthedrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def9f57c459f24986d7c90</td>\n",
       "      <td>575</td>\n",
       "      <td>by the editorial board</td>\n",
       "      <td>article</td>\n",
       "      <td>venezuelas descent into dictatorship</td>\n",
       "      <td>venezuela politics and government maduro nicolas</td>\n",
       "      <td>3</td>\n",
       "      <td>editorial</td>\n",
       "      <td>22</td>\n",
       "      <td>20170401 005306</td>\n",
       "      <td>unknown</td>\n",
       "      <td>a court ruling annulling the legislatures auth...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>editorial</td>\n",
       "      <td>httpswwwnytimescom20170331opinionvenezuelasdes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58defd317c459f24986d7c95</td>\n",
       "      <td>1374</td>\n",
       "      <td>by michael powell</td>\n",
       "      <td>article</td>\n",
       "      <td>stain permeates basketball blue blood</td>\n",
       "      <td>basketball college university of north carolin...</td>\n",
       "      <td>3</td>\n",
       "      <td>sports</td>\n",
       "      <td>1</td>\n",
       "      <td>20170401 010652</td>\n",
       "      <td>college basketball</td>\n",
       "      <td>for two decades until 2013 north carolina enga...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>news</td>\n",
       "      <td>httpswwwnytimescom20170331sportsncaabasketball...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstract                 articleID  articleWordCount  \\\n",
       "0       NaN  58def1347c459f24986d7c80               716   \n",
       "1       NaN  58def3237c459f24986d7c84               823   \n",
       "2       NaN  58def9f57c459f24986d7c90               575   \n",
       "3       NaN  58defd317c459f24986d7c95              1374   \n",
       "\n",
       "                                byline documentType  \\\n",
       "0  by stephen hiltner and susan lehman      article   \n",
       "1                      by gail collins      article   \n",
       "2               by the editorial board      article   \n",
       "3                    by michael powell      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  finding an expansive view  of a forgotten peop...   \n",
       "1                   and now  the dreaded trump curse   \n",
       "2               venezuelas descent into dictatorship   \n",
       "3              stain permeates basketball blue blood   \n",
       "\n",
       "                                            keywords  multimedia    newDesk  \\\n",
       "0  photography new york times niger ferguson adam...           3    insider   \n",
       "1  united states politics and government trump do...           3       oped   \n",
       "2   venezuela politics and government maduro nicolas           3  editorial   \n",
       "3  basketball college university of north carolin...           3     sports   \n",
       "\n",
       "   printPage          pubDate         sectionName  \\\n",
       "0          2  20170401 001541             unknown   \n",
       "1         23  20170401 002358             unknown   \n",
       "2         22  20170401 005306             unknown   \n",
       "3          1  20170401 010652  college basketball   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  one of the largest photo displays in times his...  the new york times   \n",
       "1                   meet the gang from under the bus  the new york times   \n",
       "2  a court ruling annulling the legislatures auth...  the new york times   \n",
       "3  for two decades until 2013 north carolina enga...  the new york times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           news  httpswwwnytimescom20170331insidernigermigrants...  \n",
       "1           oped  httpswwwnytimescom20170331opinionandnowthedrea...  \n",
       "2      editorial  httpswwwnytimescom20170331opinionvenezuelasdes...  \n",
       "3           news  httpswwwnytimescom20170331sportsncaabasketball...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "sent_token = nltk.sent_tokenize\n",
    "import csv  \n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "file_path = '/root/Springboard/Data/cleaned_article_data.csv'\n",
    "clean_art2 = pd.read_csv(file_path, index_col = False)\n",
    "clean_art2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(clean_art2)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix\n",
    "\n",
    "vocab = cv.get_feature_names()\n",
    "# show document feature vectors\n",
    "pd.DataFrame(cv_matrix, columns=vocab)\n",
    "\n",
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "#bv_matrix = bv.fit_transform(clean_art2)\n",
    "\n",
    "#bv_matrix = bv_matrix.toarray()\n",
    "#vocab = bv.get_feature_names()\n",
    "#pd.DataFrame(bv_matrix, columns=vocab)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "tv_matrix = tv.fit_transform(clean_art2)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(tv_matrix)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "#similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approveDate              int64\n",
       "commentBody              int64\n",
       "commentID                int64\n",
       "commentSequence          int64\n",
       "commentTitle             int64\n",
       "commentType              int64\n",
       "createDate               int64\n",
       "depth                    int64\n",
       "editorsSelection         int64\n",
       "parentID                 int64\n",
       "parentUserDisplayName    int64\n",
       "permID                   int64\n",
       "picURL                   int64\n",
       "recommendations          int64\n",
       "recommendedFlag          int64\n",
       "replyCount               int64\n",
       "reportAbuseFlag          int64\n",
       "sharing                  int64\n",
       "status                   int64\n",
       "timespeople              int64\n",
       "trusted                  int64\n",
       "updateDate               int64\n",
       "userDisplayName          int64\n",
       "userID                   int64\n",
       "userLocation             int64\n",
       "userTitle                int64\n",
       "userURL                  int64\n",
       "inReplyTo                int64\n",
       "articleID                int64\n",
       "sectionName              int64\n",
       "newDesk                  int64\n",
       "articleWordCount         int64\n",
       "printPage                int64\n",
       "typeOfMaterial           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '/root/Springboard/Data/cleaned_comment_data.csv'\n",
    "clean_comments = pd.read_csv(file_path, index_col = False)\n",
    "\n",
    "for index, column in enumerate(clean_comments):\n",
    "    clean_comments[column] = clean_comments[column].fillna(0)\n",
    "\n",
    "clean_comments.head(5)\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "features = clean_comments.columns.tolist()\n",
    "output = 'recommendations'\n",
    "features.remove('recommendations')\n",
    "\n",
    "for column in clean_comments.columns:\n",
    "    clean_comments[column] = clean_comments[column].astype(str)\n",
    "    if clean_comments[column].dtype == type(object):\n",
    "        clean_comments[column] = le.fit_transform(clean_comments[column])\n",
    "\n",
    "#print(features)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "clean_comments.astype(int)\n",
    "clean_comments.head(5)\n",
    "\n",
    "#clean_comments.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/root/.local/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012265</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 5}</td>\n",
       "      <td>0.018116</td>\n",
       "      <td>0.063725</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.036497</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035743</td>\n",
       "      <td>0.009296</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 10}</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.107843</td>\n",
       "      <td>0.146739</td>\n",
       "      <td>0.104651</td>\n",
       "      <td>0.054878</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.040969</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.231393</td>\n",
       "      <td>0.034865</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 100}</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.040094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018620</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 5}</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.039002</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036018</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 10}</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.098837</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.324497</td>\n",
       "      <td>0.060506</td>\n",
       "      <td>0.010231</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 30, 'n_estimators': 100}</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.122093</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.044509</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.017787</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 100, 'n_estimators': 5}</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.104651</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.025331</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 100, 'n_estimators': 10}</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.039416</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.329197</td>\n",
       "      <td>0.059610</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 100, 'n_estimators': 100}</td>\n",
       "      <td>0.025362</td>\n",
       "      <td>0.093137</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.012265      0.002222         0.001674        0.000266   \n",
       "1       0.035743      0.009296         0.002700        0.000572   \n",
       "2       0.231393      0.034865         0.010233        0.000443   \n",
       "3       0.018620      0.003477         0.001511        0.000153   \n",
       "4       0.036018      0.006170         0.001958        0.000062   \n",
       "5       0.324497      0.060506         0.010231        0.000775   \n",
       "6       0.017787      0.003288         0.001473        0.000201   \n",
       "7       0.034286      0.006247         0.001937        0.000135   \n",
       "8       0.329197      0.059610         0.010740        0.000944   \n",
       "\n",
       "  param_max_depth param_n_estimators                                   params  \\\n",
       "0              10                  5     {'max_depth': 10, 'n_estimators': 5}   \n",
       "1              10                 10    {'max_depth': 10, 'n_estimators': 10}   \n",
       "2              10                100   {'max_depth': 10, 'n_estimators': 100}   \n",
       "3              30                  5     {'max_depth': 30, 'n_estimators': 5}   \n",
       "4              30                 10    {'max_depth': 30, 'n_estimators': 10}   \n",
       "5              30                100   {'max_depth': 30, 'n_estimators': 100}   \n",
       "6             100                  5    {'max_depth': 100, 'n_estimators': 5}   \n",
       "7             100                 10   {'max_depth': 100, 'n_estimators': 10}   \n",
       "8             100                100  {'max_depth': 100, 'n_estimators': 100}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.018116           0.063725           0.119565           0.093023   \n",
       "1           0.036232           0.107843           0.146739           0.104651   \n",
       "2           0.032609           0.117647           0.130435           0.127907   \n",
       "3           0.032609           0.088235           0.141304           0.116279   \n",
       "4           0.021739           0.078431           0.152174           0.098837   \n",
       "5           0.021739           0.102941           0.141304           0.122093   \n",
       "6           0.043478           0.068627           0.108696           0.104651   \n",
       "7           0.028986           0.068627           0.125000           0.127907   \n",
       "8           0.025362           0.093137           0.152174           0.127907   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.048780            0.064        0.036497                9  \n",
       "1           0.054878            0.086        0.040969                5  \n",
       "2           0.085366            0.093        0.040094                1  \n",
       "3           0.097561            0.089        0.039002                2  \n",
       "4           0.091463            0.082        0.044434                7  \n",
       "5           0.091463            0.089        0.044509                2  \n",
       "6           0.079268            0.077        0.025331                8  \n",
       "7           0.097561            0.083        0.039416                6  \n",
       "8           0.073171            0.088        0.046433                4  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "param = {'n_estimators': [5,10,100],\n",
    "         'max_depth': [10, 30, 100] }\n",
    "\n",
    "gs=GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs_fit = gs.fit(clean_comments[features], clean_comments[output])\n",
    "pd.DataFrame(gs_fit.cv_results_).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
