{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Here I will document my method for cleaning my data files, which were taken from Kaggle's dataset “Comments on articles published in the New York Times” (https://www.kaggle.com/aashita/nyt-comments).\n",
    "\n",
    "This code is broken into two sections - one cleans the data files with articles and one cleans the data files with comments. Here I test my cleaning using only a single file, but by concatenating data files together, I can run this code on the entire dataset.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>716</td>\n",
       "      <td>By STEPHEN HILTNER and SUSAN LEHMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>Finding an Expansive View  of a Forgotten Peop...</td>\n",
       "      <td>['Photography', 'New York Times', 'Niger', 'Fe...</td>\n",
       "      <td>3</td>\n",
       "      <td>Insider</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-01 00:15:41</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>One of the largest photo displays in Times his...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/insider/nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def3237c459f24986d7c84</td>\n",
       "      <td>823</td>\n",
       "      <td>By GAIL COLLINS</td>\n",
       "      <td>article</td>\n",
       "      <td>And Now,  the Dreaded Trump Curse</td>\n",
       "      <td>['United States Politics and Government', 'Tru...</td>\n",
       "      <td>3</td>\n",
       "      <td>OpEd</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-04-01 00:23:58</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Meet the gang from under the bus.</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Op-Ed</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/opinion/and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def9f57c459f24986d7c90</td>\n",
       "      <td>575</td>\n",
       "      <td>By THE EDITORIAL BOARD</td>\n",
       "      <td>article</td>\n",
       "      <td>Venezuela’s Descent Into Dictatorship</td>\n",
       "      <td>['Venezuela', 'Politics and Government', 'Madu...</td>\n",
       "      <td>3</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-04-01 00:53:06</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>A court ruling annulling the legislature’s aut...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/opinion/ven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58defd317c459f24986d7c95</td>\n",
       "      <td>1374</td>\n",
       "      <td>By MICHAEL POWELL</td>\n",
       "      <td>article</td>\n",
       "      <td>Stain Permeates Basketball Blue Blood</td>\n",
       "      <td>['Basketball (College)', 'University of North ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sports</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-01 01:06:52</td>\n",
       "      <td>College Basketball</td>\n",
       "      <td>For two decades, until 2013, North Carolina en...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/sports/ncaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58df09b77c459f24986d7ca7</td>\n",
       "      <td>708</td>\n",
       "      <td>By DEB AMLEN</td>\n",
       "      <td>article</td>\n",
       "      <td>Taking Things for Granted</td>\n",
       "      <td>['Crossword Puzzles']</td>\n",
       "      <td>3</td>\n",
       "      <td>Games</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-01 02:00:14</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>In which Howard Barkin and Will Shortz teach u...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/crosswords/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract                 articleID  articleWordCount  \\\n",
       "0      NaN  58def1347c459f24986d7c80               716   \n",
       "1      NaN  58def3237c459f24986d7c84               823   \n",
       "2      NaN  58def9f57c459f24986d7c90               575   \n",
       "3      NaN  58defd317c459f24986d7c95              1374   \n",
       "4      NaN  58df09b77c459f24986d7ca7               708   \n",
       "\n",
       "                                byline documentType  \\\n",
       "0  By STEPHEN HILTNER and SUSAN LEHMAN      article   \n",
       "1                      By GAIL COLLINS      article   \n",
       "2               By THE EDITORIAL BOARD      article   \n",
       "3                    By MICHAEL POWELL      article   \n",
       "4                         By DEB AMLEN      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Finding an Expansive View  of a Forgotten Peop...   \n",
       "1                  And Now,  the Dreaded Trump Curse   \n",
       "2              Venezuela’s Descent Into Dictatorship   \n",
       "3              Stain Permeates Basketball Blue Blood   \n",
       "4                          Taking Things for Granted   \n",
       "\n",
       "                                            keywords  multimedia    newDesk  \\\n",
       "0  ['Photography', 'New York Times', 'Niger', 'Fe...           3    Insider   \n",
       "1  ['United States Politics and Government', 'Tru...           3       OpEd   \n",
       "2  ['Venezuela', 'Politics and Government', 'Madu...           3  Editorial   \n",
       "3  ['Basketball (College)', 'University of North ...           3     Sports   \n",
       "4                              ['Crossword Puzzles']           3      Games   \n",
       "\n",
       "   printPage              pubDate         sectionName  \\\n",
       "0          2  2017-04-01 00:15:41             Unknown   \n",
       "1         23  2017-04-01 00:23:58             Unknown   \n",
       "2         22  2017-04-01 00:53:06             Unknown   \n",
       "3          1  2017-04-01 01:06:52  College Basketball   \n",
       "4          0  2017-04-01 02:00:14             Unknown   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  One of the largest photo displays in Times his...  The New York Times   \n",
       "1                  Meet the gang from under the bus.  The New York Times   \n",
       "2  A court ruling annulling the legislature’s aut...  The New York Times   \n",
       "3  For two decades, until 2013, North Carolina en...  The New York Times   \n",
       "4  In which Howard Barkin and Will Shortz teach u...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2017/03/31/insider/nig...  \n",
       "1          Op-Ed  https://www.nytimes.com/2017/03/31/opinion/and...  \n",
       "2      Editorial  https://www.nytimes.com/2017/03/31/opinion/ven...  \n",
       "3           News  https://www.nytimes.com/2017/03/31/sports/ncaa...  \n",
       "4           News  https://www.nytimes.com/2017/03/31/crosswords/...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "import re\n",
    "sent_token = nltk.sent_tokenize\n",
    "import csv  \n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#For all data - train = pd.read_csv(\"/root/Springboard/Data/cleaning/allArticles.csv\")\n",
    "train = pd.read_csv(r\"C:\\Users\\msteele9\\Documents\\Springboard\\Springboard\\Data\\ArticlesApril2017.csv\")\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Initial goals: \n",
    "\n",
    "-Make sure the contents of each field are the correct type and have no missing data (i.e. scrub the 'NaN' from the 'abstract' field)\n",
    "\n",
    "-Make sure that the data comes properly tokenized\n",
    "\n",
    "-Convert all words to lowercase (to avoid confusion between uppercase and lowercase versions of the same word)\n",
    "\n",
    "Several of these data columns (articleID, articleWordCount, multimedia, printPage) contain only integers or single lowercase words.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n",
      "int64    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n",
      "int64    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n",
      "int64    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n",
      "object    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('wordnet')\n",
    "for column in train:\n",
    "    print(train[column].get_dtype_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>From the above code, the only integer columns are 2, 7 and 9. The rest are string columns and need to be converted to lowercase. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>716</td>\n",
       "      <td>by stephen hiltner and susan lehman</td>\n",
       "      <td>article</td>\n",
       "      <td>finding an expansive view  of a forgotten peop...</td>\n",
       "      <td>photography new york times niger ferguson adam...</td>\n",
       "      <td>3</td>\n",
       "      <td>insider</td>\n",
       "      <td>2</td>\n",
       "      <td>20170401 001541</td>\n",
       "      <td>unknown</td>\n",
       "      <td>one of the largest photo displays in times his...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>news</td>\n",
       "      <td>httpswwwnytimescom20170331insidernigermigrants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan</td>\n",
       "      <td>58def3237c459f24986d7c84</td>\n",
       "      <td>823</td>\n",
       "      <td>by gail collins</td>\n",
       "      <td>article</td>\n",
       "      <td>and now  the dreaded trump curse</td>\n",
       "      <td>united states politics and government trump do...</td>\n",
       "      <td>3</td>\n",
       "      <td>oped</td>\n",
       "      <td>23</td>\n",
       "      <td>20170401 002358</td>\n",
       "      <td>unknown</td>\n",
       "      <td>meet the gang from under the bus</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>oped</td>\n",
       "      <td>httpswwwnytimescom20170331opinionandnowthedrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>58def9f57c459f24986d7c90</td>\n",
       "      <td>575</td>\n",
       "      <td>by the editorial board</td>\n",
       "      <td>article</td>\n",
       "      <td>venezuelas descent into dictatorship</td>\n",
       "      <td>venezuela politics and government maduro nicolas</td>\n",
       "      <td>3</td>\n",
       "      <td>editorial</td>\n",
       "      <td>22</td>\n",
       "      <td>20170401 005306</td>\n",
       "      <td>unknown</td>\n",
       "      <td>a court ruling annulling the legislatures auth...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>editorial</td>\n",
       "      <td>httpswwwnytimescom20170331opinionvenezuelasdes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nan</td>\n",
       "      <td>58defd317c459f24986d7c95</td>\n",
       "      <td>1374</td>\n",
       "      <td>by michael powell</td>\n",
       "      <td>article</td>\n",
       "      <td>stain permeates basketball blue blood</td>\n",
       "      <td>basketball college university of north carolin...</td>\n",
       "      <td>3</td>\n",
       "      <td>sports</td>\n",
       "      <td>1</td>\n",
       "      <td>20170401 010652</td>\n",
       "      <td>college basketball</td>\n",
       "      <td>for two decades until 2013 north carolina enga...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>news</td>\n",
       "      <td>httpswwwnytimescom20170331sportsncaabasketball...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan</td>\n",
       "      <td>58df09b77c459f24986d7ca7</td>\n",
       "      <td>708</td>\n",
       "      <td>by deb amlen</td>\n",
       "      <td>article</td>\n",
       "      <td>taking things for granted</td>\n",
       "      <td>crossword puzzles</td>\n",
       "      <td>3</td>\n",
       "      <td>games</td>\n",
       "      <td>0</td>\n",
       "      <td>20170401 020014</td>\n",
       "      <td>unknown</td>\n",
       "      <td>in which howard barkin and will shortz teach u...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>news</td>\n",
       "      <td>httpswwwnytimescom20170331crosswordstakingthin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract                 articleID articleWordCount  \\\n",
       "0      nan  58def1347c459f24986d7c80              716   \n",
       "1      nan  58def3237c459f24986d7c84              823   \n",
       "2      nan  58def9f57c459f24986d7c90              575   \n",
       "3      nan  58defd317c459f24986d7c95             1374   \n",
       "4      nan  58df09b77c459f24986d7ca7              708   \n",
       "\n",
       "                                byline documentType  \\\n",
       "0  by stephen hiltner and susan lehman      article   \n",
       "1                      by gail collins      article   \n",
       "2               by the editorial board      article   \n",
       "3                    by michael powell      article   \n",
       "4                         by deb amlen      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  finding an expansive view  of a forgotten peop...   \n",
       "1                   and now  the dreaded trump curse   \n",
       "2               venezuelas descent into dictatorship   \n",
       "3              stain permeates basketball blue blood   \n",
       "4                          taking things for granted   \n",
       "\n",
       "                                            keywords multimedia    newDesk  \\\n",
       "0  photography new york times niger ferguson adam...          3    insider   \n",
       "1  united states politics and government trump do...          3       oped   \n",
       "2   venezuela politics and government maduro nicolas          3  editorial   \n",
       "3  basketball college university of north carolin...          3     sports   \n",
       "4                                  crossword puzzles          3      games   \n",
       "\n",
       "  printPage          pubDate         sectionName  \\\n",
       "0         2  20170401 001541             unknown   \n",
       "1        23  20170401 002358             unknown   \n",
       "2        22  20170401 005306             unknown   \n",
       "3         1  20170401 010652  college basketball   \n",
       "4         0  20170401 020014             unknown   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  one of the largest photo displays in times his...  the new york times   \n",
       "1                   meet the gang from under the bus  the new york times   \n",
       "2  a court ruling annulling the legislatures auth...  the new york times   \n",
       "3  for two decades until 2013 north carolina enga...  the new york times   \n",
       "4  in which howard barkin and will shortz teach u...  the new york times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           news  httpswwwnytimescom20170331insidernigermigrants...  \n",
       "1           oped  httpswwwnytimescom20170331opinionandnowthedrea...  \n",
       "2      editorial  httpswwwnytimescom20170331opinionvenezuelasdes...  \n",
       "3           news  httpswwwnytimescom20170331sportsncaabasketball...  \n",
       "4           news  httpswwwnytimescom20170331crosswordstakingthin...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize = 4000000\n",
    "train = pd.read_csv(r\"C:\\Users\\msteele9\\Documents\\Springboard\\Springboard\\Data\\ArticlesApril2017.csv\", header=0, nrows=sampleSize)\n",
    "#train.head(5)\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "nonstrings = [2, 7, 9]\n",
    "\n",
    "\n",
    "train= train.astype(str)\n",
    "train.fillna(0)\n",
    "\n",
    "def clean_articles(doc):\n",
    "    for index, column in enumerate(doc):\n",
    "        if index in nonstrings:\n",
    "            doc[column] = doc[column].astype(str)\n",
    "            continue\n",
    "        doc[column] = doc[column].str.replace('[^\\w\\s]','')\n",
    "        doc[column] = doc[column].str.lower()\n",
    "        #doc[column] = doc[column].str.strip()\n",
    "        doc[column] = doc[column].replace(np.nan, ' ', regex=True)\n",
    "        doc[column].apply(nltk.word_tokenize)\n",
    "        doc[column].apply(lemmatize_text)\n",
    "        doc[column] = [token for token in doc[column] if token not in stop_words]\n",
    "    return doc\n",
    "\n",
    "def lemmatize_text(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "clean_art = clean_articles(train)\n",
    "\n",
    "clean_art.head(5)\n",
    "\n",
    "#print('\\n'.join(clean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>To be safe, I want to check for cells that have missing elements. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any null values left: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Any null values left: \"),\n",
    "clean_art.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Now we want a separate section to clean the comment files. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msteele9\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3044: DtypeWarning: Columns (25,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approveDate</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>commentID</th>\n",
       "      <th>commentSequence</th>\n",
       "      <th>commentTitle</th>\n",
       "      <th>commentType</th>\n",
       "      <th>createDate</th>\n",
       "      <th>depth</th>\n",
       "      <th>editorsSelection</th>\n",
       "      <th>parentID</th>\n",
       "      <th>parentUserDisplayName</th>\n",
       "      <th>permID</th>\n",
       "      <th>picURL</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>recommendedFlag</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>reportAbuseFlag</th>\n",
       "      <th>sharing</th>\n",
       "      <th>status</th>\n",
       "      <th>timespeople</th>\n",
       "      <th>trusted</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>userDisplayName</th>\n",
       "      <th>userID</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userTitle</th>\n",
       "      <th>userURL</th>\n",
       "      <th>inReplyTo</th>\n",
       "      <th>articleID</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>printPage</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1491245186</td>\n",
       "      <td>this project makes me happy to be a 30 year ti...</td>\n",
       "      <td>22022598.0</td>\n",
       "      <td>22022598</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491237056.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>22022598</td>\n",
       "      <td>https://graphics8.nytimes.com/images/apps/time...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>approved</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1491245186</td>\n",
       "      <td>rob gayle</td>\n",
       "      <td>46006296</td>\n",
       "      <td>riverside ca</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1491188619</td>\n",
       "      <td>stunning photos and reportage infuriating that...</td>\n",
       "      <td>22017350.0</td>\n",
       "      <td>22017350</td>\n",
       "      <td>nan</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491180489.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>22017350</td>\n",
       "      <td>https://graphics8.nytimes.com/images/apps/time...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>approved</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1491188619</td>\n",
       "      <td>susan a</td>\n",
       "      <td>29202761</td>\n",
       "      <td>br</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1491188617</td>\n",
       "      <td>brilliant work from conception to execution iv...</td>\n",
       "      <td>22017334.0</td>\n",
       "      <td>22017334</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491179470.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>22017334</td>\n",
       "      <td>https://graphics8.nytimes.com/images/apps/time...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>approved</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1491188617</td>\n",
       "      <td>meta</td>\n",
       "      <td>63944806</td>\n",
       "      <td>raleigh nc</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1491167820</td>\n",
       "      <td>nyt reporters should provide a contributors li...</td>\n",
       "      <td>22015913.0</td>\n",
       "      <td>22015913</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491150196.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>22015913</td>\n",
       "      <td>https://graphics8.nytimes.com/images/apps/time...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>approved</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1491167820</td>\n",
       "      <td>tom wyrick</td>\n",
       "      <td>1266184</td>\n",
       "      <td>missouri usa</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1491167815</td>\n",
       "      <td>could only have been done in print stunning</td>\n",
       "      <td>22015466.0</td>\n",
       "      <td>22015466</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491147284.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>22015466</td>\n",
       "      <td>http://profile.ak.fbcdn.net/hprofile-ak-snc4/h...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>approved</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1491167815</td>\n",
       "      <td>joe sharkey</td>\n",
       "      <td>61121360</td>\n",
       "      <td>tucson arizona</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  approveDate                                        commentBody   commentID  \\\n",
       "0  1491245186  this project makes me happy to be a 30 year ti...  22022598.0   \n",
       "1  1491188619  stunning photos and reportage infuriating that...  22017350.0   \n",
       "2  1491188617  brilliant work from conception to execution iv...  22017334.0   \n",
       "3  1491167820  nyt reporters should provide a contributors li...  22015913.0   \n",
       "4  1491167815       could only have been done in print stunning   22015466.0   \n",
       "\n",
       "  commentSequence commentTitle commentType    createDate depth  \\\n",
       "0        22022598        <br/>     comment  1491237056.0     1   \n",
       "1        22017350          nan     comment  1491180489.0     1   \n",
       "2        22017334        <br/>     comment  1491179470.0     1   \n",
       "3        22015913        <br/>     comment  1491150196.0     1   \n",
       "4        22015466        <br/>     comment  1491147284.0     1   \n",
       "\n",
       "  editorsSelection parentID parentUserDisplayName    permID  \\\n",
       "0            False      0.0                   nan  22022598   \n",
       "1            False      0.0                   nan  22017350   \n",
       "2            False      0.0                   nan  22017334   \n",
       "3            False      0.0                   nan  22015913   \n",
       "4            False      0.0                   nan  22015466   \n",
       "\n",
       "                                              picURL recommendations  \\\n",
       "0  https://graphics8.nytimes.com/images/apps/time...             2.0   \n",
       "1  https://graphics8.nytimes.com/images/apps/time...             1.0   \n",
       "2  https://graphics8.nytimes.com/images/apps/time...             3.0   \n",
       "3  https://graphics8.nytimes.com/images/apps/time...             7.0   \n",
       "4  http://profile.ak.fbcdn.net/hprofile-ak-snc4/h...             5.0   \n",
       "\n",
       "  recommendedFlag replyCount reportAbuseFlag sharing    status timespeople  \\\n",
       "0             nan        0.0             nan       0  approved         1.0   \n",
       "1             nan        0.0             nan       0  approved         1.0   \n",
       "2             nan        0.0             nan       0  approved         1.0   \n",
       "3             nan        2.0             nan       0  approved         1.0   \n",
       "4             nan        0.0             nan       0  approved         1.0   \n",
       "\n",
       "  trusted  updateDate userDisplayName    userID    userLocation userTitle  \\\n",
       "0     0.0  1491245186       rob gayle  46006296    riverside ca       nan   \n",
       "1     0.0  1491188619         susan a  29202761              br       nan   \n",
       "2     0.0  1491188617            meta  63944806      raleigh nc       nan   \n",
       "3     0.0  1491167820      tom wyrick   1266184    missouri usa       nan   \n",
       "4     0.0  1491167815     joe sharkey  61121360  tucson arizona       nan   \n",
       "\n",
       "  userURL inReplyTo                 articleID sectionName  newDesk  \\\n",
       "0     nan         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "1     nan         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "2     nan         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "3     nan         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "4     nan         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "\n",
       "  articleWordCount printPage typeOfMaterial  \n",
       "0            716.0         2           news  \n",
       "1            716.0         2           news  \n",
       "2            716.0         2           news  \n",
       "3            716.0         2           news  \n",
       "4            716.0         2           news  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For all data - train = pd.read_csv(\"/root/Springboard/Data/cleaning/allComments.csv\")\n",
    "\n",
    "sampleSize = 100000\n",
    "train = pd.read_csv(r\"C:\\Users\\msteele9\\Documents\\Springboard\\CommentsApril2017.csv\", nrows=sampleSize)\n",
    "\n",
    "train= train.astype(str)\n",
    "train.fillna(0)\n",
    "strings = [1, 5, 10, 18, 22, 24, 25, 26, 29, 30, 33]\n",
    "\n",
    "def lemmatize_text(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "def clean_articles(doc):\n",
    "    for index, column in enumerate(doc):\n",
    "        if index in strings:         \n",
    "            doc[column] = doc[column].str.replace('[^\\w\\s]','')\n",
    "            doc[column] = doc[column].str.lower()\n",
    "            #doc[column] = doc[column].str.strip()\n",
    "            doc[column] = doc[column].replace(np.nan, '', regex=True)\n",
    "            doc[column].apply(nltk.word_tokenize)\n",
    "            doc[column].apply(lemmatize_text)\n",
    "            doc[column].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "        else:\n",
    "            doc[column] = doc[column].astype(str)\n",
    "            continue\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(norm_articles)\n",
    "\n",
    "clean_comments = clean_articles(train)\n",
    "#The second command takes awhile to run\n",
    "clean_comments.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any null values left: \n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Any null values left: \"), print(clean_comments.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that I am saving the files where I want\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\msteele9\\Documents\\Springboard\\Springboard\\Data')\n",
    "art_file_name = \"cleaned_article_data.csv\"\n",
    "clean_art_csv = clean_art.to_csv(art_file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_file_name = \"cleaned_comment_data.csv\"\n",
    "clean_com_csv = clean_comments.to_csv(com_file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Here I have saved the cleaned data files to storage. This is a good break point where I can use these files to begin looking at possible ML models. \n",
    "    \n",
    "   In the next section, I will explore the data, looking at features and ways to visualize the feature set. I begin by re-importing the libraries that I will use. That way, this section of the notebook can be reran separately later. I will load the cleaned files in so that I know I am not making any changes to the stored version.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#ntlk.download()\n",
    "import re\n",
    "sent_token = nltk.sent_tokenize\n",
    "import csv  \n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "file_path_art = r'C:\\Users\\msteele9\\Documents\\Springboard\\Springboard\\Data\\cleaned_article_data.csv'\n",
    "clean_art = pd.read_csv(file_path_art, index_col = False)\n",
    "clean_art\n",
    "\n",
    "file_path_comments = r'C:\\Users\\msteele9\\Documents\\Springboard\\Springboard\\Data\\cleaned_comment_data.csv'\n",
    "clean_comments = pd.read_csv(file_path_comments, index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> In the above cell, I loaded in the cleaned article data. Here I load in the cleaned data and do preprocessing to run the data through a random forest model. \n",
    "    \n",
    "   I want to make sure that my data can actually be loaded and that my simple test will produce results of some sort - this way I know that my data will not break when I try to load it.\n",
    "   \n",
    "   My target is the number of recommendations that the comment receives. I want to know how well a simple model can predict the number of recommendations a comment will receive when given the rest of that comment's data.\n",
    "</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approveDate</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>commentID</th>\n",
       "      <th>commentSequence</th>\n",
       "      <th>commentTitle</th>\n",
       "      <th>commentType</th>\n",
       "      <th>createDate</th>\n",
       "      <th>depth</th>\n",
       "      <th>editorsSelection</th>\n",
       "      <th>parentID</th>\n",
       "      <th>parentUserDisplayName</th>\n",
       "      <th>permID</th>\n",
       "      <th>picURL</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>recommendedFlag</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>reportAbuseFlag</th>\n",
       "      <th>sharing</th>\n",
       "      <th>status</th>\n",
       "      <th>timespeople</th>\n",
       "      <th>trusted</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>userDisplayName</th>\n",
       "      <th>userID</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userTitle</th>\n",
       "      <th>userURL</th>\n",
       "      <th>inReplyTo</th>\n",
       "      <th>articleID</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>printPage</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5675</td>\n",
       "      <td>82175</td>\n",
       "      <td>10692</td>\n",
       "      <td>10692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5571</td>\n",
       "      <td>11368</td>\n",
       "      <td>98</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5887</td>\n",
       "      <td>21206</td>\n",
       "      <td>9821</td>\n",
       "      <td>5970</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>222</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3457</td>\n",
       "      <td>67130</td>\n",
       "      <td>7166</td>\n",
       "      <td>7166</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5571</td>\n",
       "      <td>7306</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3648</td>\n",
       "      <td>23831</td>\n",
       "      <td>5481</td>\n",
       "      <td>935</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>222</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3456</td>\n",
       "      <td>11257</td>\n",
       "      <td>7160</td>\n",
       "      <td>7160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5571</td>\n",
       "      <td>7301</td>\n",
       "      <td>98</td>\n",
       "      <td>387</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3647</td>\n",
       "      <td>16895</td>\n",
       "      <td>19981</td>\n",
       "      <td>5828</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>222</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3292</td>\n",
       "      <td>54786</td>\n",
       "      <td>6606</td>\n",
       "      <td>6606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5571</td>\n",
       "      <td>6844</td>\n",
       "      <td>98</td>\n",
       "      <td>745</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3473</td>\n",
       "      <td>24897</td>\n",
       "      <td>659</td>\n",
       "      <td>4372</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>222</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3291</td>\n",
       "      <td>14150</td>\n",
       "      <td>6385</td>\n",
       "      <td>6385</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5571</td>\n",
       "      <td>6688</td>\n",
       "      <td>73</td>\n",
       "      <td>592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3472</td>\n",
       "      <td>12207</td>\n",
       "      <td>17732</td>\n",
       "      <td>7277</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>222</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   approveDate  commentBody  commentID  commentSequence  commentTitle  \\\n",
       "0         5675        82175      10692            10692             0   \n",
       "1         3457        67130       7166             7166             1   \n",
       "2         3456        11257       7160             7160             0   \n",
       "3         3292        54786       6606             6606             0   \n",
       "4         3291        14150       6385             6385             0   \n",
       "\n",
       "   commentType  createDate  depth  editorsSelection  parentID  \\\n",
       "0            0       10239      0                 0         0   \n",
       "1            0        6940      0                 0         0   \n",
       "2            0        6934      0                 0         0   \n",
       "3            0        6388      0                 0         0   \n",
       "4            0        6176      0                 0         0   \n",
       "\n",
       "   parentUserDisplayName  permID  picURL  recommendations  recommendedFlag  \\\n",
       "0                   5571   11368      98              247                0   \n",
       "1                   5571    7306      98                1                0   \n",
       "2                   5571    7301      98              387                0   \n",
       "3                   5571    6844      98              745                0   \n",
       "4                   5571    6688      73              592                0   \n",
       "\n",
       "   replyCount  reportAbuseFlag  sharing  status  timespeople  trusted  \\\n",
       "0           0                0        0       0            1        0   \n",
       "1           0                0        0       0            1        0   \n",
       "2           0                0        0       0            1        0   \n",
       "3          15                0        0       0            1        0   \n",
       "4           0                0        0       0            1        0   \n",
       "\n",
       "   updateDate  userDisplayName  userID  userLocation  userTitle  userURL  \\\n",
       "0        5887            21206    9821          5970          0        1   \n",
       "1        3648            23831    5481           935          0        1   \n",
       "2        3647            16895   19981          5828          0        1   \n",
       "3        3473            24897     659          4372          0        1   \n",
       "4        3472            12207   17732          7277          0        1   \n",
       "\n",
       "   inReplyTo  articleID  sectionName  newDesk  articleWordCount  printPage  \\\n",
       "0          0          0           26        9               222         12   \n",
       "1          0          0           26        9               222         12   \n",
       "2          0          0           26        9               222         12   \n",
       "3          0          0           26        9               222         12   \n",
       "4          0          0           26        9               222         12   \n",
       "\n",
       "   typeOfMaterial  \n",
       "0               5  \n",
       "1               5  \n",
       "2               5  \n",
       "3               5  \n",
       "4               5  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "features = clean_comments.columns.tolist()\n",
    "output = 'recommendations'\n",
    "features.remove('recommendations')\n",
    "\n",
    "for column in clean_comments.columns:\n",
    "    clean_comments[column] = clean_comments[column].astype(str)\n",
    "    if clean_comments[column].dtype == type(object):\n",
    "        clean_comments[column] = le.fit_transform(clean_comments[column])\n",
    "\n",
    "#print(features)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "clean_comments.astype(int)\n",
    "clean_comments.head(5)\n",
    "\n",
    "#clean_comments.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "param = {'n_estimators': [5,10,100, 200, 500, 1000],\n",
    "         'max_depth': [5, 10, 30, 100, 1000] }\n",
    "\n",
    "gs=GridSearchCV(rf, param, cv=5, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.687200</td>\n",
       "      <td>0.075735</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 500}</td>\n",
       "      <td>0.061594</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.135870</td>\n",
       "      <td>0.180233</td>\n",
       "      <td>0.134146</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.042060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266600</td>\n",
       "      <td>0.035364</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 200}</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.142157</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.174419</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.039246</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.401199</td>\n",
       "      <td>0.168370</td>\n",
       "      <td>0.095801</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 1000}</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>0.142157</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.180233</td>\n",
       "      <td>0.115854</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 5}</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.115854</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.020420</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131799</td>\n",
       "      <td>0.021302</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 100}</td>\n",
       "      <td>0.050725</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.135870</td>\n",
       "      <td>0.174419</td>\n",
       "      <td>0.128049</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.044132</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4       0.687200      0.075735         0.047400        0.002417   \n",
       "3       0.266600      0.035364         0.018600        0.001200   \n",
       "5       1.401199      0.168370         0.095801        0.004996   \n",
       "0       0.008200      0.000748         0.001802        0.000400   \n",
       "2       0.131799      0.021302         0.010000        0.000894   \n",
       "\n",
       "  param_max_depth param_n_estimators                                  params  \\\n",
       "4               5                500   {'max_depth': 5, 'n_estimators': 500}   \n",
       "3               5                200   {'max_depth': 5, 'n_estimators': 200}   \n",
       "5               5               1000  {'max_depth': 5, 'n_estimators': 1000}   \n",
       "0               5                  5     {'max_depth': 5, 'n_estimators': 5}   \n",
       "2               5                100   {'max_depth': 5, 'n_estimators': 100}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "4           0.061594           0.147059           0.135870           0.180233   \n",
       "3           0.065217           0.142157           0.125000           0.174419   \n",
       "5           0.072464           0.142157           0.125000           0.180233   \n",
       "0           0.086957           0.132353           0.130435           0.139535   \n",
       "2           0.050725           0.137255           0.135870           0.174419   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "4           0.134146            0.125        0.042060                1  \n",
       "3           0.146341            0.124        0.039246                2  \n",
       "5           0.115854            0.122        0.036759                3  \n",
       "0           0.115854            0.118        0.020420                4  \n",
       "2           0.128049            0.118        0.044132                4  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_fit.cv_results_).sort_values(by=['rank_test_score']).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> A quick GridSearch with a random forest classifier was able run on my data set and produce an accuracy score. The highest-performing model (mean score 0.125) used a high number of trees (500) and a low max tree depth (5). The models with more trees performed better, but the results are clumped fairly close together. All of the top performers used the minimum allowed tree depth.\n",
    "    \n",
    "   My goal was to confirm that I can run ML algorithms on my data set and get sensible results; this test seems to verify this.\n",
    "</font> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
