{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here I will document my method for cleaning my data files, which were taken from Kaggle's dataset “Comments on articles published in the New York Times” (https://www.kaggle.com/aashita/nyt-comments).\n",
    "    \n",
    "This code is broken into two sections - one cleans the data files with articles and one cleans the data files with comments. Here I test my cleaning using only a single file, but by concatenating data files together, I can run this code on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>716</td>\n",
       "      <td>By STEPHEN HILTNER and SUSAN LEHMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>Finding an Expansive View  of a Forgotten Peop...</td>\n",
       "      <td>['Photography', 'New York Times', 'Niger', 'Fe...</td>\n",
       "      <td>3</td>\n",
       "      <td>Insider</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-01 00:15:41</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>One of the largest photo displays in Times his...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/insider/nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def3237c459f24986d7c84</td>\n",
       "      <td>823</td>\n",
       "      <td>By GAIL COLLINS</td>\n",
       "      <td>article</td>\n",
       "      <td>And Now,  the Dreaded Trump Curse</td>\n",
       "      <td>['United States Politics and Government', 'Tru...</td>\n",
       "      <td>3</td>\n",
       "      <td>OpEd</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-04-01 00:23:58</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Meet the gang from under the bus.</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Op-Ed</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/opinion/and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def9f57c459f24986d7c90</td>\n",
       "      <td>575</td>\n",
       "      <td>By THE EDITORIAL BOARD</td>\n",
       "      <td>article</td>\n",
       "      <td>Venezuela’s Descent Into Dictatorship</td>\n",
       "      <td>['Venezuela', 'Politics and Government', 'Madu...</td>\n",
       "      <td>3</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-04-01 00:53:06</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>A court ruling annulling the legislature’s aut...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/opinion/ven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58defd317c459f24986d7c95</td>\n",
       "      <td>1374</td>\n",
       "      <td>By MICHAEL POWELL</td>\n",
       "      <td>article</td>\n",
       "      <td>Stain Permeates Basketball Blue Blood</td>\n",
       "      <td>['Basketball (College)', 'University of North ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sports</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-01 01:06:52</td>\n",
       "      <td>College Basketball</td>\n",
       "      <td>For two decades, until 2013, North Carolina en...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/sports/ncaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58df09b77c459f24986d7ca7</td>\n",
       "      <td>708</td>\n",
       "      <td>By DEB AMLEN</td>\n",
       "      <td>article</td>\n",
       "      <td>Taking Things for Granted</td>\n",
       "      <td>['Crossword Puzzles']</td>\n",
       "      <td>3</td>\n",
       "      <td>Games</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-01 02:00:14</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>In which Howard Barkin and Will Shortz teach u...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/crosswords/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract                 articleID  articleWordCount  \\\n",
       "0      NaN  58def1347c459f24986d7c80               716   \n",
       "1      NaN  58def3237c459f24986d7c84               823   \n",
       "2      NaN  58def9f57c459f24986d7c90               575   \n",
       "3      NaN  58defd317c459f24986d7c95              1374   \n",
       "4      NaN  58df09b77c459f24986d7ca7               708   \n",
       "\n",
       "                                byline documentType  \\\n",
       "0  By STEPHEN HILTNER and SUSAN LEHMAN      article   \n",
       "1                      By GAIL COLLINS      article   \n",
       "2               By THE EDITORIAL BOARD      article   \n",
       "3                    By MICHAEL POWELL      article   \n",
       "4                         By DEB AMLEN      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Finding an Expansive View  of a Forgotten Peop...   \n",
       "1                  And Now,  the Dreaded Trump Curse   \n",
       "2              Venezuela’s Descent Into Dictatorship   \n",
       "3              Stain Permeates Basketball Blue Blood   \n",
       "4                          Taking Things for Granted   \n",
       "\n",
       "                                            keywords  multimedia    newDesk  \\\n",
       "0  ['Photography', 'New York Times', 'Niger', 'Fe...           3    Insider   \n",
       "1  ['United States Politics and Government', 'Tru...           3       OpEd   \n",
       "2  ['Venezuela', 'Politics and Government', 'Madu...           3  Editorial   \n",
       "3  ['Basketball (College)', 'University of North ...           3     Sports   \n",
       "4                              ['Crossword Puzzles']           3      Games   \n",
       "\n",
       "   printPage              pubDate         sectionName  \\\n",
       "0          2  2017-04-01 00:15:41             Unknown   \n",
       "1         23  2017-04-01 00:23:58             Unknown   \n",
       "2         22  2017-04-01 00:53:06             Unknown   \n",
       "3          1  2017-04-01 01:06:52  College Basketball   \n",
       "4          0  2017-04-01 02:00:14             Unknown   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  One of the largest photo displays in Times his...  The New York Times   \n",
       "1                  Meet the gang from under the bus.  The New York Times   \n",
       "2  A court ruling annulling the legislature’s aut...  The New York Times   \n",
       "3  For two decades, until 2013, North Carolina en...  The New York Times   \n",
       "4  In which Howard Barkin and Will Shortz teach u...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2017/03/31/insider/nig...  \n",
       "1          Op-Ed  https://www.nytimes.com/2017/03/31/opinion/and...  \n",
       "2      Editorial  https://www.nytimes.com/2017/03/31/opinion/ven...  \n",
       "3           News  https://www.nytimes.com/2017/03/31/sports/ncaa...  \n",
       "4           News  https://www.nytimes.com/2017/03/31/crosswords/...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "import re\n",
    "sent_token = nltk.sent_tokenize\n",
    "import csv  \n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#For all data - train = pd.read_csv(\"/root/Springboard/Data/cleaning/allArticles.csv\")\n",
    "train = pd.read_csv(r\"C:\\Users\\msteele9\\Documents\\Springboard\\Springboard\\Data\\ArticlesApril2017.csv\")\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial goals: \n",
    "\n",
    "-Make sure the contents of each field are the correct type and have no missing data (i.e. scrub the 'NaN' from the 'abstract' field)\n",
    "\n",
    "-Make sure that the data comes properly tokenized\n",
    "\n",
    "-Convert all words to lowercase (to avoid confusion between uppercase and lowercase versions of the same word)\n",
    "\n",
    "Several of these data columns (articleID, articleWordCount, multimedia, printPage) contain only integers or single lowercase words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object    13\n",
      "int64      3\n",
      "dtype: int64\n",
      "\n",
      "object\n",
      "object\n",
      "int64\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "int64\n",
      "object\n",
      "int64\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "#nltk.download('wordnet')\n",
    "#for column in train:\n",
    "    #print(train[column].get_dtype_counts())\n",
    "    \n",
    "print(train.dtypes.value_counts())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "for column in train:\n",
    "    print(train[column].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### From the above code, the only integer columns are 2, 7 and 9. The rest are string columns and need to be converted to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>716</td>\n",
       "      <td>by stephen hiltner and susan lehman</td>\n",
       "      <td>article</td>\n",
       "      <td>finding an expansive view  of a forgotten peop...</td>\n",
       "      <td>photography new york times niger ferguson adam...</td>\n",
       "      <td>3</td>\n",
       "      <td>insider</td>\n",
       "      <td>2</td>\n",
       "      <td>20170401 001541</td>\n",
       "      <td>unknown</td>\n",
       "      <td>one of the largest photo displays in times his...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>news</td>\n",
       "      <td>httpswwwnytimescom20170331insidernigermigrants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan</td>\n",
       "      <td>58def3237c459f24986d7c84</td>\n",
       "      <td>823</td>\n",
       "      <td>by gail collins</td>\n",
       "      <td>article</td>\n",
       "      <td>and now  the dreaded trump curse</td>\n",
       "      <td>united states politics and government trump do...</td>\n",
       "      <td>3</td>\n",
       "      <td>oped</td>\n",
       "      <td>23</td>\n",
       "      <td>20170401 002358</td>\n",
       "      <td>unknown</td>\n",
       "      <td>meet the gang from under the bus</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>oped</td>\n",
       "      <td>httpswwwnytimescom20170331opinionandnowthedrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>58def9f57c459f24986d7c90</td>\n",
       "      <td>575</td>\n",
       "      <td>by the editorial board</td>\n",
       "      <td>article</td>\n",
       "      <td>venezuelas descent into dictatorship</td>\n",
       "      <td>venezuela politics and government maduro nicolas</td>\n",
       "      <td>3</td>\n",
       "      <td>editorial</td>\n",
       "      <td>22</td>\n",
       "      <td>20170401 005306</td>\n",
       "      <td>unknown</td>\n",
       "      <td>a court ruling annulling the legislatures auth...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>editorial</td>\n",
       "      <td>httpswwwnytimescom20170331opinionvenezuelasdes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nan</td>\n",
       "      <td>58defd317c459f24986d7c95</td>\n",
       "      <td>1374</td>\n",
       "      <td>by michael powell</td>\n",
       "      <td>article</td>\n",
       "      <td>stain permeates basketball blue blood</td>\n",
       "      <td>basketball college university of north carolin...</td>\n",
       "      <td>3</td>\n",
       "      <td>sports</td>\n",
       "      <td>1</td>\n",
       "      <td>20170401 010652</td>\n",
       "      <td>college basketball</td>\n",
       "      <td>for two decades until 2013 north carolina enga...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>news</td>\n",
       "      <td>httpswwwnytimescom20170331sportsncaabasketball...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nan</td>\n",
       "      <td>58df09b77c459f24986d7ca7</td>\n",
       "      <td>708</td>\n",
       "      <td>by deb amlen</td>\n",
       "      <td>article</td>\n",
       "      <td>taking things for granted</td>\n",
       "      <td>crossword puzzles</td>\n",
       "      <td>3</td>\n",
       "      <td>games</td>\n",
       "      <td>0</td>\n",
       "      <td>20170401 020014</td>\n",
       "      <td>unknown</td>\n",
       "      <td>in which howard barkin and will shortz teach u...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>news</td>\n",
       "      <td>httpswwwnytimescom20170331crosswordstakingthin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract                 articleID articleWordCount  \\\n",
       "0      nan  58def1347c459f24986d7c80              716   \n",
       "1      nan  58def3237c459f24986d7c84              823   \n",
       "2      nan  58def9f57c459f24986d7c90              575   \n",
       "3      nan  58defd317c459f24986d7c95             1374   \n",
       "4      nan  58df09b77c459f24986d7ca7              708   \n",
       "\n",
       "                                byline documentType  \\\n",
       "0  by stephen hiltner and susan lehman      article   \n",
       "1                      by gail collins      article   \n",
       "2               by the editorial board      article   \n",
       "3                    by michael powell      article   \n",
       "4                         by deb amlen      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  finding an expansive view  of a forgotten peop...   \n",
       "1                   and now  the dreaded trump curse   \n",
       "2               venezuelas descent into dictatorship   \n",
       "3              stain permeates basketball blue blood   \n",
       "4                          taking things for granted   \n",
       "\n",
       "                                            keywords multimedia    newDesk  \\\n",
       "0  photography new york times niger ferguson adam...          3    insider   \n",
       "1  united states politics and government trump do...          3       oped   \n",
       "2   venezuela politics and government maduro nicolas          3  editorial   \n",
       "3  basketball college university of north carolin...          3     sports   \n",
       "4                                  crossword puzzles          3      games   \n",
       "\n",
       "  printPage          pubDate         sectionName  \\\n",
       "0         2  20170401 001541             unknown   \n",
       "1        23  20170401 002358             unknown   \n",
       "2        22  20170401 005306             unknown   \n",
       "3         1  20170401 010652  college basketball   \n",
       "4         0  20170401 020014             unknown   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  one of the largest photo displays in times his...  the new york times   \n",
       "1                   meet the gang from under the bus  the new york times   \n",
       "2  a court ruling annulling the legislatures auth...  the new york times   \n",
       "3  for two decades until 2013 north carolina enga...  the new york times   \n",
       "4  in which howard barkin and will shortz teach u...  the new york times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           news  httpswwwnytimescom20170331insidernigermigrants...  \n",
       "1           oped  httpswwwnytimescom20170331opinionandnowthedrea...  \n",
       "2      editorial  httpswwwnytimescom20170331opinionvenezuelasdes...  \n",
       "3           news  httpswwwnytimescom20170331sportsncaabasketball...  \n",
       "4           news  httpswwwnytimescom20170331crosswordstakingthin...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize = 4000000\n",
    "train = pd.read_csv(r\"C:\\Users\\msteele9\\Documents\\Springboard\\Springboard\\Data\\ArticlesApril2017.csv\", header=0, nrows=sampleSize)\n",
    "#train.head(5)\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "nonstrings = [2, 7, 9]\n",
    "\n",
    "\n",
    "train= train.astype(str)\n",
    "train.fillna(0)\n",
    "\n",
    "def clean_articles(doc):\n",
    "    for index, column in enumerate(doc):\n",
    "        if index in nonstrings:\n",
    "            doc[column] = doc[column].astype(str)\n",
    "            continue\n",
    "        doc[column] = doc[column].str.replace('[^\\w\\s]','')\n",
    "        doc[column] = doc[column].str.lower()\n",
    "        #doc[column] = doc[column].str.strip()\n",
    "        doc[column] = doc[column].replace(np.nan, ' ', regex=True)\n",
    "        doc[column].apply(nltk.word_tokenize)\n",
    "        doc[column].apply(lemmatize_text)\n",
    "        doc[column] = [token for token in doc[column] if token not in stop_words]     \n",
    "    return doc\n",
    "\n",
    "def lemmatize_text(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "clean_art = clean_articles(train)\n",
    "\n",
    "clean_art.head(5)\n",
    "\n",
    "#print('\\n'.join(clean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### I want to check for cells that have missing elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any null values left: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Any null values left: \"),\n",
    "clean_art.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now we want a separate section to clean the comment files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approveDate</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>commentID</th>\n",
       "      <th>commentSequence</th>\n",
       "      <th>commentTitle</th>\n",
       "      <th>commentType</th>\n",
       "      <th>createDate</th>\n",
       "      <th>depth</th>\n",
       "      <th>editorsSelection</th>\n",
       "      <th>parentID</th>\n",
       "      <th>...</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userTitle</th>\n",
       "      <th>userURL</th>\n",
       "      <th>inReplyTo</th>\n",
       "      <th>articleID</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>printPage</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1491245186</td>\n",
       "      <td>this project makes me happy to be a 30 year ti...</td>\n",
       "      <td>22022598.0</td>\n",
       "      <td>22022598</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491237056.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>riverside ca</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1491188619</td>\n",
       "      <td>stunning photos and reportage infuriating that...</td>\n",
       "      <td>22017350.0</td>\n",
       "      <td>22017350</td>\n",
       "      <td>nan</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491180489.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1491188617</td>\n",
       "      <td>brilliant work from conception to execution iv...</td>\n",
       "      <td>22017334.0</td>\n",
       "      <td>22017334</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491179470.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>raleigh nc</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1491167820</td>\n",
       "      <td>nyt reporters should provide a contributors li...</td>\n",
       "      <td>22015913.0</td>\n",
       "      <td>22015913</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491150196.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>missouri usa</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1491167815</td>\n",
       "      <td>could only have been done in print stunning</td>\n",
       "      <td>22015466.0</td>\n",
       "      <td>22015466</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491147284.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>tucson arizona</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  approveDate                                        commentBody   commentID  \\\n",
       "0  1491245186  this project makes me happy to be a 30 year ti...  22022598.0   \n",
       "1  1491188619  stunning photos and reportage infuriating that...  22017350.0   \n",
       "2  1491188617  brilliant work from conception to execution iv...  22017334.0   \n",
       "3  1491167820  nyt reporters should provide a contributors li...  22015913.0   \n",
       "4  1491167815       could only have been done in print stunning   22015466.0   \n",
       "\n",
       "  commentSequence commentTitle commentType    createDate depth  \\\n",
       "0        22022598        <br/>     comment  1491237056.0     1   \n",
       "1        22017350          nan     comment  1491180489.0     1   \n",
       "2        22017334        <br/>     comment  1491179470.0     1   \n",
       "3        22015913        <br/>     comment  1491150196.0     1   \n",
       "4        22015466        <br/>     comment  1491147284.0     1   \n",
       "\n",
       "  editorsSelection parentID  ...    userLocation userTitle userURL inReplyTo  \\\n",
       "0            False      0.0  ...    riverside ca       nan     nan         0   \n",
       "1            False      0.0  ...              br       nan     nan         0   \n",
       "2            False      0.0  ...      raleigh nc       nan     nan         0   \n",
       "3            False      0.0  ...    missouri usa       nan     nan         0   \n",
       "4            False      0.0  ...  tucson arizona       nan     nan         0   \n",
       "\n",
       "                  articleID sectionName  newDesk articleWordCount printPage  \\\n",
       "0  58def1347c459f24986d7c80     unknown  insider            716.0         2   \n",
       "1  58def1347c459f24986d7c80     unknown  insider            716.0         2   \n",
       "2  58def1347c459f24986d7c80     unknown  insider            716.0         2   \n",
       "3  58def1347c459f24986d7c80     unknown  insider            716.0         2   \n",
       "4  58def1347c459f24986d7c80     unknown  insider            716.0         2   \n",
       "\n",
       "  typeOfMaterial  \n",
       "0           news  \n",
       "1           news  \n",
       "2           news  \n",
       "3           news  \n",
       "4           news  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For all data - train = pd.read_csv(\"/root/Springboard/Data/cleaning/allComments.csv\")\n",
    "\n",
    "sampleSize = 10000\n",
    "train = pd.read_csv(r\"C:\\Users\\msteele9\\Documents\\Springboard\\CommentsApril2017.csv\", nrows=sampleSize)\n",
    "\n",
    "train= train.astype(str)\n",
    "train.fillna(0)\n",
    "strings = [1, 5, 10, 18, 22, 24, 25, 26, 29, 30, 33]\n",
    "\n",
    "def lemmatize_text(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "def clean_articles(doc):\n",
    "    for index, column in enumerate(doc):\n",
    "        if index in strings:         \n",
    "            doc[column] = doc[column].str.replace('[^\\w\\s]','')\n",
    "            doc[column] = doc[column].str.lower()\n",
    "            #doc[column] = doc[column].str.strip()\n",
    "            doc[column] = doc[column].replace(np.nan, '', regex=True)\n",
    "            doc[column].apply(nltk.word_tokenize)\n",
    "            doc[column].apply(lemmatize_text)\n",
    "            doc[column].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "        else:\n",
    "            doc[column] = doc[column].astype(str)\n",
    "            continue\n",
    "    return doc\n",
    "\n",
    "clean_comments = clean_articles(train)\n",
    "#The second command takes awhile to run\n",
    "clean_comments.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any null values left: \n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Any null values left: \"), print(clean_comments.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approveDate               5073\n",
       "commentBody               9994\n",
       "commentID                10000\n",
       "commentSequence          10000\n",
       "commentTitle                 2\n",
       "commentType                  3\n",
       "createDate                9715\n",
       "depth                        3\n",
       "editorsSelection             2\n",
       "parentID                  1646\n",
       "parentUserDisplayName     1302\n",
       "permID                   10000\n",
       "picURL                     781\n",
       "recommendations            358\n",
       "recommendedFlag              1\n",
       "replyCount                  24\n",
       "reportAbuseFlag              1\n",
       "sharing                      2\n",
       "status                       1\n",
       "timespeople                  1\n",
       "trusted                      2\n",
       "updateDate                5380\n",
       "userDisplayName           5118\n",
       "userID                    6293\n",
       "userLocation              2242\n",
       "userTitle                    2\n",
       "userURL                      2\n",
       "inReplyTo                 1646\n",
       "articleID                   37\n",
       "sectionName                  8\n",
       "newDesk                     12\n",
       "articleWordCount            37\n",
       "printPage                   13\n",
       "typeOfMaterial               4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comments.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see that there are no null values remaining, but looking at the dataframe I see that several columns contain nothing but 'nan' strings or otherwise have only one value. I want to drop the commentTitle (contains only <br/> or nan), recommendedFlag, reportAbuseFlag, status, timespeople, userTitle and userURL columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approveDate</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>commentID</th>\n",
       "      <th>commentSequence</th>\n",
       "      <th>commentType</th>\n",
       "      <th>createDate</th>\n",
       "      <th>depth</th>\n",
       "      <th>editorsSelection</th>\n",
       "      <th>parentID</th>\n",
       "      <th>parentUserDisplayName</th>\n",
       "      <th>...</th>\n",
       "      <th>userDisplayName</th>\n",
       "      <th>userID</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>inReplyTo</th>\n",
       "      <th>articleID</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>printPage</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1491245186</td>\n",
       "      <td>this project makes me happy to be a 30 year ti...</td>\n",
       "      <td>22022598.0</td>\n",
       "      <td>22022598</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491237056.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>rob gayle</td>\n",
       "      <td>46006296</td>\n",
       "      <td>riverside ca</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1491188619</td>\n",
       "      <td>stunning photos and reportage infuriating that...</td>\n",
       "      <td>22017350.0</td>\n",
       "      <td>22017350</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491180489.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>susan a</td>\n",
       "      <td>29202761</td>\n",
       "      <td>br</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1491188617</td>\n",
       "      <td>brilliant work from conception to execution iv...</td>\n",
       "      <td>22017334.0</td>\n",
       "      <td>22017334</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491179470.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>meta</td>\n",
       "      <td>63944806</td>\n",
       "      <td>raleigh nc</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1491167820</td>\n",
       "      <td>nyt reporters should provide a contributors li...</td>\n",
       "      <td>22015913.0</td>\n",
       "      <td>22015913</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491150196.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>tom wyrick</td>\n",
       "      <td>1266184</td>\n",
       "      <td>missouri usa</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1491167815</td>\n",
       "      <td>could only have been done in print stunning</td>\n",
       "      <td>22015466.0</td>\n",
       "      <td>22015466</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491147284.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>joe sharkey</td>\n",
       "      <td>61121360</td>\n",
       "      <td>tucson arizona</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1491142576</td>\n",
       "      <td>thank you new york times people should be supp...</td>\n",
       "      <td>22012085.0</td>\n",
       "      <td>22012085</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491128692.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>dramaman</td>\n",
       "      <td>59125002</td>\n",
       "      <td>new york</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1491060909</td>\n",
       "      <td>proof that photojournalism is alive and well e...</td>\n",
       "      <td>22003784.0</td>\n",
       "      <td>22003784</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491056012.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>bob williams</td>\n",
       "      <td>320791</td>\n",
       "      <td>east northport ny</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1491252241</td>\n",
       "      <td>the oasis initiative which i started with prof...</td>\n",
       "      <td>22024897.0</td>\n",
       "      <td>22024897</td>\n",
       "      <td>userreply</td>\n",
       "      <td>1491247899.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>22015913.0</td>\n",
       "      <td>tom wyrick</td>\n",
       "      <td>...</td>\n",
       "      <td>alisha g</td>\n",
       "      <td>65289571</td>\n",
       "      <td>tahoma ca</td>\n",
       "      <td>22015913</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1491668599</td>\n",
       "      <td>i agree ive just spent 30 minutes trying to fi...</td>\n",
       "      <td>22082978.0</td>\n",
       "      <td>22082978</td>\n",
       "      <td>userreply</td>\n",
       "      <td>1491665056.0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>22015913.0</td>\n",
       "      <td>tom wyrick</td>\n",
       "      <td>...</td>\n",
       "      <td>kathy mortensen</td>\n",
       "      <td>76442479</td>\n",
       "      <td>ann arbor</td>\n",
       "      <td>22015913</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1491064414</td>\n",
       "      <td>how about katrina pierson back to palookaville...</td>\n",
       "      <td>22004930.0</td>\n",
       "      <td>22004930</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491061051.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>...</td>\n",
       "      <td>gaucho54</td>\n",
       "      <td>59237391</td>\n",
       "      <td>california</td>\n",
       "      <td>0</td>\n",
       "      <td>58def3237c459f24986d7c84</td>\n",
       "      <td>unknown</td>\n",
       "      <td>oped</td>\n",
       "      <td>823.0</td>\n",
       "      <td>23</td>\n",
       "      <td>oped</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  approveDate                                        commentBody   commentID  \\\n",
       "0  1491245186  this project makes me happy to be a 30 year ti...  22022598.0   \n",
       "1  1491188619  stunning photos and reportage infuriating that...  22017350.0   \n",
       "2  1491188617  brilliant work from conception to execution iv...  22017334.0   \n",
       "3  1491167820  nyt reporters should provide a contributors li...  22015913.0   \n",
       "4  1491167815       could only have been done in print stunning   22015466.0   \n",
       "5  1491142576  thank you new york times people should be supp...  22012085.0   \n",
       "6  1491060909  proof that photojournalism is alive and well e...  22003784.0   \n",
       "7  1491252241  the oasis initiative which i started with prof...  22024897.0   \n",
       "8  1491668599  i agree ive just spent 30 minutes trying to fi...  22082978.0   \n",
       "9  1491064414  how about katrina pierson back to palookaville...  22004930.0   \n",
       "\n",
       "  commentSequence commentType    createDate depth editorsSelection  \\\n",
       "0        22022598     comment  1491237056.0     1            False   \n",
       "1        22017350     comment  1491180489.0     1            False   \n",
       "2        22017334     comment  1491179470.0     1            False   \n",
       "3        22015913     comment  1491150196.0     1            False   \n",
       "4        22015466     comment  1491147284.0     1            False   \n",
       "5        22012085     comment  1491128692.0     1            False   \n",
       "6        22003784     comment  1491056012.0     1            False   \n",
       "7        22024897   userreply  1491247899.0     2            False   \n",
       "8        22082978   userreply  1491665056.0     2            False   \n",
       "9        22004930     comment  1491061051.0     1            False   \n",
       "\n",
       "     parentID parentUserDisplayName  ...  userDisplayName    userID  \\\n",
       "0         0.0                   nan  ...        rob gayle  46006296   \n",
       "1         0.0                   nan  ...          susan a  29202761   \n",
       "2         0.0                   nan  ...             meta  63944806   \n",
       "3         0.0                   nan  ...       tom wyrick   1266184   \n",
       "4         0.0                   nan  ...      joe sharkey  61121360   \n",
       "5         0.0                   nan  ...         dramaman  59125002   \n",
       "6         0.0                   nan  ...     bob williams    320791   \n",
       "7  22015913.0            tom wyrick  ...         alisha g  65289571   \n",
       "8  22015913.0            tom wyrick  ...  kathy mortensen  76442479   \n",
       "9         0.0                   nan  ...         gaucho54  59237391   \n",
       "\n",
       "        userLocation inReplyTo                 articleID sectionName  newDesk  \\\n",
       "0       riverside ca         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "1                 br         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "2         raleigh nc         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "3       missouri usa         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "4     tucson arizona         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "5           new york         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "6  east northport ny         0  58def1347c459f24986d7c80     unknown  insider   \n",
       "7          tahoma ca  22015913  58def1347c459f24986d7c80     unknown  insider   \n",
       "8          ann arbor  22015913  58def1347c459f24986d7c80     unknown  insider   \n",
       "9         california         0  58def3237c459f24986d7c84     unknown     oped   \n",
       "\n",
       "  articleWordCount printPage typeOfMaterial  \n",
       "0            716.0         2           news  \n",
       "1            716.0         2           news  \n",
       "2            716.0         2           news  \n",
       "3            716.0         2           news  \n",
       "4            716.0         2           news  \n",
       "5            716.0         2           news  \n",
       "6            716.0         2           news  \n",
       "7            716.0         2           news  \n",
       "8            716.0         2           news  \n",
       "9            823.0        23           oped  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comments.drop(columns=['commentTitle', 'recommendedFlag', 'reportAbuseFlag', 'status', 'timespeople', 'userTitle', 'userURL'], axis=1, inplace=True)\n",
    "\n",
    "clean_comments.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### I check my working directory to make sure I am saving the files where I want them stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import os\n",
    "os.chdir(r'C:\\Users\\msteele9\\Documents\\Springboard\\Springboard\\Data')\n",
    "art_file_name = \"cleaned_article_data.csv\"\n",
    "clean_art_csv = clean_art.to_csv(art_file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_file_name = \"cleaned_comment_data.csv\"\n",
    "clean_com_csv = clean_comments.to_csv(com_file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Here I have saved the cleaned data files to storage. This is a good break point where I can use these files to begin looking at possible ML models. \n",
    "    \n",
    "   In the next section, I will explore the data, looking at features and ways to visualize the feature set. I begin by re-importing the libraries that I will use. That way, this section of the notebook can be reran separately later. I will load the cleaned files in so that I know I am not making any changes to the stored version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#ntlk.download()\n",
    "import re\n",
    "sent_token = nltk.sent_tokenize\n",
    "import csv  \n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "file_path_art = r'C:\\Users\\msteele9\\Documents\\Springboard\\Springboard\\Data\\cleaned_article_data.csv'\n",
    "clean_art = pd.read_csv(file_path_art, index_col = False)\n",
    "clean_art\n",
    "\n",
    "file_path_comments = r'C:\\Users\\msteele9\\Documents\\Springboard\\Springboard\\Data\\cleaned_comment_data.csv'\n",
    "clean_comments = pd.read_csv(file_path_comments, index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In the above cell, I loaded in the cleaned article data. Here I load in the cleaned data and do preprocessing to run the data through a random forest model. \n",
    "    \n",
    "   I want to make sure that my data can actually be loaded and that my simple test will produce results of some sort - this way I know that my data will not break when I try to load it.\n",
    "   \n",
    "   My target is the number of recommendations that the comment receives. I want to know how well a simple model can predict the number of recommendations a comment will receive when given the rest of that comment's data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approveDate</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>commentID</th>\n",
       "      <th>commentSequence</th>\n",
       "      <th>commentType</th>\n",
       "      <th>createDate</th>\n",
       "      <th>depth</th>\n",
       "      <th>editorsSelection</th>\n",
       "      <th>parentID</th>\n",
       "      <th>parentUserDisplayName</th>\n",
       "      <th>permID</th>\n",
       "      <th>picURL</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>sharing</th>\n",
       "      <th>trusted</th>\n",
       "      <th>updateDate</th>\n",
       "      <th>userDisplayName</th>\n",
       "      <th>userID</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>inReplyTo</th>\n",
       "      <th>articleID</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>printPage</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4183</td>\n",
       "      <td>8195</td>\n",
       "      <td>8329</td>\n",
       "      <td>8329</td>\n",
       "      <td>0</td>\n",
       "      <td>8081</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>887</td>\n",
       "      <td>8671</td>\n",
       "      <td>17</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4385</td>\n",
       "      <td>4112</td>\n",
       "      <td>1801</td>\n",
       "      <td>1639</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3457</td>\n",
       "      <td>6605</td>\n",
       "      <td>7166</td>\n",
       "      <td>7166</td>\n",
       "      <td>0</td>\n",
       "      <td>6940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>887</td>\n",
       "      <td>7306</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3648</td>\n",
       "      <td>4600</td>\n",
       "      <td>975</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3456</td>\n",
       "      <td>1089</td>\n",
       "      <td>7160</td>\n",
       "      <td>7160</td>\n",
       "      <td>0</td>\n",
       "      <td>6934</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>887</td>\n",
       "      <td>7301</td>\n",
       "      <td>17</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3647</td>\n",
       "      <td>3254</td>\n",
       "      <td>3698</td>\n",
       "      <td>1603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3292</td>\n",
       "      <td>5470</td>\n",
       "      <td>6606</td>\n",
       "      <td>6606</td>\n",
       "      <td>0</td>\n",
       "      <td>6388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>887</td>\n",
       "      <td>6844</td>\n",
       "      <td>17</td>\n",
       "      <td>298</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3473</td>\n",
       "      <td>4795</td>\n",
       "      <td>108</td>\n",
       "      <td>1187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3291</td>\n",
       "      <td>1347</td>\n",
       "      <td>6385</td>\n",
       "      <td>6385</td>\n",
       "      <td>0</td>\n",
       "      <td>6176</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>887</td>\n",
       "      <td>6688</td>\n",
       "      <td>14</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3472</td>\n",
       "      <td>2341</td>\n",
       "      <td>3302</td>\n",
       "      <td>2016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   approveDate  commentBody  commentID  commentSequence  commentType  \\\n",
       "0         4183         8195       8329             8329            0   \n",
       "1         3457         6605       7166             7166            0   \n",
       "2         3456         1089       7160             7160            0   \n",
       "3         3292         5470       6606             6606            0   \n",
       "4         3291         1347       6385             6385            0   \n",
       "\n",
       "   createDate  depth  editorsSelection  parentID  parentUserDisplayName  \\\n",
       "0        8081      0                 0         0                    887   \n",
       "1        6940      0                 0         0                    887   \n",
       "2        6934      0                 0         0                    887   \n",
       "3        6388      0                 0         0                    887   \n",
       "4        6176      0                 0         0                    887   \n",
       "\n",
       "   permID  picURL  recommendations  replyCount  sharing  trusted  updateDate  \\\n",
       "0    8671      17              110           0        0        0        4385   \n",
       "1    7306      17                1           0        0        0        3648   \n",
       "2    7301      17              167           0        0        0        3647   \n",
       "3    6844      17              298          11        0        0        3473   \n",
       "4    6688      14              243           0        0        0        3472   \n",
       "\n",
       "   userDisplayName  userID  userLocation  inReplyTo  articleID  sectionName  \\\n",
       "0             4112    1801          1639          0          0            7   \n",
       "1             4600     975           267          0          0            7   \n",
       "2             3254    3698          1603          0          0            7   \n",
       "3             4795     108          1187          0          0            7   \n",
       "4             2341    3302          2016          0          0            7   \n",
       "\n",
       "   newDesk  articleWordCount  printPage  typeOfMaterial  \n",
       "0        4                29          4               1  \n",
       "1        4                29          4               1  \n",
       "2        4                29          4               1  \n",
       "3        4                29          4               1  \n",
       "4        4                29          4               1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "features = clean_comments.columns.tolist()\n",
    "output = 'recommendations'\n",
    "features.remove('recommendations')\n",
    "\n",
    "for column in clean_comments.columns:\n",
    "    clean_comments[column] = clean_comments[column].astype(str)\n",
    "    if clean_comments[column].dtype == type(object):\n",
    "        clean_comments[column] = le.fit_transform(clean_comments[column])\n",
    "\n",
    "#print(features)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "clean_comments.astype(float)\n",
    "clean_comments.head(5)\n",
    "\n",
    "#clean_comments.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msteele9\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\msteele9\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "param = {'n_estimators': [5, 10, 25],\n",
    "         'max_depth': [5, 10, 20, 50] }\n",
    "\n",
    "gs=GridSearchCV(rf, param, cv=5, n_jobs=5)\n",
    "\n",
    "gs_fit = gs.fit(clean_comments[features], clean_comments[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.242198</td>\n",
       "      <td>0.047237</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.011983</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 10}</td>\n",
       "      <td>0.109312</td>\n",
       "      <td>0.100149</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.223754</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.056561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583198</td>\n",
       "      <td>0.106234</td>\n",
       "      <td>0.128599</td>\n",
       "      <td>0.037398</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 25}</td>\n",
       "      <td>0.097166</td>\n",
       "      <td>0.105107</td>\n",
       "      <td>0.049566</td>\n",
       "      <td>0.107981</td>\n",
       "      <td>0.223754</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.056288</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.115798</td>\n",
       "      <td>0.020683</td>\n",
       "      <td>0.028802</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 5}</td>\n",
       "      <td>0.084570</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.067961</td>\n",
       "      <td>0.117893</td>\n",
       "      <td>0.221103</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.053688</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.446998</td>\n",
       "      <td>0.079622</td>\n",
       "      <td>0.038001</td>\n",
       "      <td>0.007293</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 10}</td>\n",
       "      <td>0.052182</td>\n",
       "      <td>0.083292</td>\n",
       "      <td>0.015841</td>\n",
       "      <td>0.094418</td>\n",
       "      <td>0.220573</td>\n",
       "      <td>0.0912</td>\n",
       "      <td>0.067978</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.137200</td>\n",
       "      <td>0.238564</td>\n",
       "      <td>0.113599</td>\n",
       "      <td>0.034302</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>{'max_depth': 10, 'n_estimators': 25}</td>\n",
       "      <td>0.062978</td>\n",
       "      <td>0.074368</td>\n",
       "      <td>0.016863</td>\n",
       "      <td>0.094418</td>\n",
       "      <td>0.190880</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.056290</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       0.242198      0.047237         0.048000        0.011983   \n",
       "2       0.583198      0.106234         0.128599        0.037398   \n",
       "0       0.115798      0.020683         0.028802        0.007985   \n",
       "4       0.446998      0.079622         0.038001        0.007293   \n",
       "5       1.137200      0.238564         0.113599        0.034302   \n",
       "\n",
       "  param_max_depth param_n_estimators                                 params  \\\n",
       "1               5                 10   {'max_depth': 5, 'n_estimators': 10}   \n",
       "2               5                 25   {'max_depth': 5, 'n_estimators': 25}   \n",
       "0               5                  5    {'max_depth': 5, 'n_estimators': 5}   \n",
       "4              10                 10  {'max_depth': 10, 'n_estimators': 10}   \n",
       "5              10                 25  {'max_depth': 10, 'n_estimators': 25}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "1           0.109312           0.100149           0.046500           0.111111   \n",
       "2           0.097166           0.105107           0.049566           0.107981   \n",
       "0           0.084570           0.090729           0.067961           0.117893   \n",
       "4           0.052182           0.083292           0.015841           0.094418   \n",
       "5           0.062978           0.074368           0.016863           0.094418   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "1           0.223754           0.1171        0.056561                1  \n",
       "2           0.223754           0.1154        0.056288                2  \n",
       "0           0.221103           0.1147        0.053688                3  \n",
       "4           0.220573           0.0912        0.067978                4  \n",
       "5           0.190880           0.0864        0.056290                5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_fit.cv_results_).sort_values(by=['rank_test_score']).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A quick GridSearch with a random forest classifier was able run on my data set and produce an accuracy score. My goal was to confirm that I can run ML algorithms on my data set and get sensible results; this test seems to verify this.\n",
    "\n",
    "Here I am looking to see what the best model is doing. Only a few of our features have a strong impact on the number of recommendations. It looks like the dominant features are the approve date and the comment body. These intuitively make sense - we expect the content of the comment to be one of if not the most important feature, and the time the comment is posted likely determines how many people will see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 20 : (approveDate) (0.130939)\n",
      "2. feature 8 : (commentBody) (0.114369)\n",
      "3. feature 22 : (commentID) (0.091900)\n",
      "4. feature 17 : (commentSequence) (0.089533)\n",
      "5. feature 15 : (commentType) (0.069414)\n",
      "6. feature 23 : (createDate) (0.065152)\n",
      "7. feature 24 : (depth) (0.059461)\n",
      "8. feature 25 : (editorsSelection) (0.055708)\n",
      "9. feature 10 : (parentID) (0.046112)\n",
      "10. feature 19 : (parentUserDisplayName) (0.044994)\n",
      "11. feature 21 : (permID) (0.039039)\n",
      "12. feature 3 : (picURL) (0.034184)\n",
      "13. feature 0 : (replyCount) (0.034116)\n",
      "14. feature 9 : (sharing) (0.024503)\n",
      "15. feature 4 : (trusted) (0.018952)\n",
      "16. feature 5 : (updateDate) (0.017675)\n",
      "17. feature 12 : (userDisplayName) (0.016609)\n",
      "18. feature 2 : (userID) (0.013633)\n",
      "19. feature 16 : (userLocation) (0.013002)\n",
      "20. feature 1 : (inReplyTo) (0.006463)\n",
      "21. feature 18 : (articleID) (0.005166)\n",
      "22. feature 11 : (sectionName) (0.004056)\n",
      "23. feature 6 : (newDesk) (0.003892)\n",
      "24. feature 14 : (articleWordCount) (0.001128)\n",
      "25. feature 13 : (printPage) (0.000000)\n",
      "26. feature 7 : (typeOfMaterial) (0.000000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = gs_fit.best_estimator_.feature_importances_\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in gs_fit.best_estimator_.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(clean_comments[features].shape[1]):\n",
    "    print(\"%d. feature %d : (%s) (%f)\" % (f + 1, indices[f], features[f], importances[indices[f]]))\n",
    "    \n",
    "    # Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(clean_comments[features].shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(clean_comments[features].shape[1]), indices)\n",
    "plt.xlim([-1, clean_comments[features].shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
