{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Here I will document my method for cleaning my data files, which were taken from Kaggle's dataset “Comments on articles published in the New York Times” (https://www.kaggle.com/aashita/nyt-comments).\n",
    "\n",
    "This code is broken into two sections - one cleans the data files with articles and one cleans the data files with comments. Here I test my cleaning using only a single file, but by concatenating data files together, I can run this code on the entire dataset.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>716</td>\n",
       "      <td>By STEPHEN HILTNER and SUSAN LEHMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>Finding an Expansive View  of a Forgotten Peop...</td>\n",
       "      <td>['Photography', 'New York Times', 'Niger', 'Fe...</td>\n",
       "      <td>3</td>\n",
       "      <td>Insider</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-04-01 00:15:41</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>One of the largest photo displays in Times his...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/insider/nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def3237c459f24986d7c84</td>\n",
       "      <td>823</td>\n",
       "      <td>By GAIL COLLINS</td>\n",
       "      <td>article</td>\n",
       "      <td>And Now,  the Dreaded Trump Curse</td>\n",
       "      <td>['United States Politics and Government', 'Tru...</td>\n",
       "      <td>3</td>\n",
       "      <td>OpEd</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-04-01 00:23:58</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Meet the gang from under the bus.</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Op-Ed</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/opinion/and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58def9f57c459f24986d7c90</td>\n",
       "      <td>575</td>\n",
       "      <td>By THE EDITORIAL BOARD</td>\n",
       "      <td>article</td>\n",
       "      <td>Venezuela’s Descent Into Dictatorship</td>\n",
       "      <td>['Venezuela', 'Politics and Government', 'Madu...</td>\n",
       "      <td>3</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>22</td>\n",
       "      <td>2017-04-01 00:53:06</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>A court ruling annulling the legislature’s aut...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>Editorial</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/opinion/ven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58defd317c459f24986d7c95</td>\n",
       "      <td>1374</td>\n",
       "      <td>By MICHAEL POWELL</td>\n",
       "      <td>article</td>\n",
       "      <td>Stain Permeates Basketball Blue Blood</td>\n",
       "      <td>['Basketball (College)', 'University of North ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Sports</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-04-01 01:06:52</td>\n",
       "      <td>College Basketball</td>\n",
       "      <td>For two decades, until 2013, North Carolina en...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/sports/ncaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>58df09b77c459f24986d7ca7</td>\n",
       "      <td>708</td>\n",
       "      <td>By DEB AMLEN</td>\n",
       "      <td>article</td>\n",
       "      <td>Taking Things for Granted</td>\n",
       "      <td>['Crossword Puzzles']</td>\n",
       "      <td>3</td>\n",
       "      <td>Games</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-01 02:00:14</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>In which Howard Barkin and Will Shortz teach u...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2017/03/31/crosswords/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract                 articleID  articleWordCount  \\\n",
       "0      NaN  58def1347c459f24986d7c80               716   \n",
       "1      NaN  58def3237c459f24986d7c84               823   \n",
       "2      NaN  58def9f57c459f24986d7c90               575   \n",
       "3      NaN  58defd317c459f24986d7c95              1374   \n",
       "4      NaN  58df09b77c459f24986d7ca7               708   \n",
       "\n",
       "                                byline documentType  \\\n",
       "0  By STEPHEN HILTNER and SUSAN LEHMAN      article   \n",
       "1                      By GAIL COLLINS      article   \n",
       "2               By THE EDITORIAL BOARD      article   \n",
       "3                    By MICHAEL POWELL      article   \n",
       "4                         By DEB AMLEN      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Finding an Expansive View  of a Forgotten Peop...   \n",
       "1                  And Now,  the Dreaded Trump Curse   \n",
       "2              Venezuela’s Descent Into Dictatorship   \n",
       "3              Stain Permeates Basketball Blue Blood   \n",
       "4                          Taking Things for Granted   \n",
       "\n",
       "                                            keywords  multimedia    newDesk  \\\n",
       "0  ['Photography', 'New York Times', 'Niger', 'Fe...           3    Insider   \n",
       "1  ['United States Politics and Government', 'Tru...           3       OpEd   \n",
       "2  ['Venezuela', 'Politics and Government', 'Madu...           3  Editorial   \n",
       "3  ['Basketball (College)', 'University of North ...           3     Sports   \n",
       "4                              ['Crossword Puzzles']           3      Games   \n",
       "\n",
       "   printPage              pubDate         sectionName  \\\n",
       "0          2  2017-04-01 00:15:41             Unknown   \n",
       "1         23  2017-04-01 00:23:58             Unknown   \n",
       "2         22  2017-04-01 00:53:06             Unknown   \n",
       "3          1  2017-04-01 01:06:52  College Basketball   \n",
       "4          0  2017-04-01 02:00:14             Unknown   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  One of the largest photo displays in Times his...  The New York Times   \n",
       "1                  Meet the gang from under the bus.  The New York Times   \n",
       "2  A court ruling annulling the legislature’s aut...  The New York Times   \n",
       "3  For two decades, until 2013, North Carolina en...  The New York Times   \n",
       "4  In which Howard Barkin and Will Shortz teach u...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2017/03/31/insider/nig...  \n",
       "1          Op-Ed  https://www.nytimes.com/2017/03/31/opinion/and...  \n",
       "2      Editorial  https://www.nytimes.com/2017/03/31/opinion/ven...  \n",
       "3           News  https://www.nytimes.com/2017/03/31/sports/ncaa...  \n",
       "4           News  https://www.nytimes.com/2017/03/31/crosswords/...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "sent_token = nltk.sent_tokenize\n",
    "import csv  \n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#For all data - train = pd.read_csv(\"/root/Springboard/Data/cleaning/allArticles.csv\")\n",
    "train = pd.read_csv(\"/root/Springboard/Data/ArticlesApril2017.csv\")\n",
    "\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Initial goals: \n",
    "\n",
    "-Make sure the contents of each field are the correct type and have no missing data (i.e. scrub the 'NaN' from the 'abstract' field)\n",
    "\n",
    "-Make sure that the data comes properly tokenized\n",
    "\n",
    "-Convert all words to lowercase (to avoid confusion between uppercase and lowercase versions of the same word)\n",
    "\n",
    "Several of these data columns (articleID, articleWordCount, multimedia, printPage) contain only integers or single lowercase words.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for column in train:\n",
    "    #print(train[column].get_dtype_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>From the above code, the only integer columns are 2, 7 and 9. The rest are string columns and need to be converted to lowercase. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>716</td>\n",
       "      <td>by stephen hiltner and susan lehman</td>\n",
       "      <td>article</td>\n",
       "      <td>finding an expansive view  of a forgotten peop...</td>\n",
       "      <td>photography new york times niger ferguson adam...</td>\n",
       "      <td>3</td>\n",
       "      <td>insider</td>\n",
       "      <td>2</td>\n",
       "      <td>20170401 001541</td>\n",
       "      <td>unknown</td>\n",
       "      <td>one of the largest photo displays in times his...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>news</td>\n",
       "      <td>httpswwwnytimescom20170331insidernigermigrants...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nan</td>\n",
       "      <td>58def3237c459f24986d7c84</td>\n",
       "      <td>823</td>\n",
       "      <td>by gail collins</td>\n",
       "      <td>article</td>\n",
       "      <td>and now  the dreaded trump curse</td>\n",
       "      <td>united states politics and government trump do...</td>\n",
       "      <td>3</td>\n",
       "      <td>oped</td>\n",
       "      <td>23</td>\n",
       "      <td>20170401 002358</td>\n",
       "      <td>unknown</td>\n",
       "      <td>meet the gang from under the bus</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>oped</td>\n",
       "      <td>httpswwwnytimescom20170331opinionandnowthedrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nan</td>\n",
       "      <td>58def9f57c459f24986d7c90</td>\n",
       "      <td>575</td>\n",
       "      <td>by the editorial board</td>\n",
       "      <td>article</td>\n",
       "      <td>venezuelas descent into dictatorship</td>\n",
       "      <td>venezuela politics and government maduro nicolas</td>\n",
       "      <td>3</td>\n",
       "      <td>editorial</td>\n",
       "      <td>22</td>\n",
       "      <td>20170401 005306</td>\n",
       "      <td>unknown</td>\n",
       "      <td>a court ruling annulling the legislatures auth...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>editorial</td>\n",
       "      <td>httpswwwnytimescom20170331opinionvenezuelasdes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nan</td>\n",
       "      <td>58defd317c459f24986d7c95</td>\n",
       "      <td>1374</td>\n",
       "      <td>by michael powell</td>\n",
       "      <td>article</td>\n",
       "      <td>stain permeates basketball blue blood</td>\n",
       "      <td>basketball college university of north carolin...</td>\n",
       "      <td>3</td>\n",
       "      <td>sports</td>\n",
       "      <td>1</td>\n",
       "      <td>20170401 010652</td>\n",
       "      <td>college basketball</td>\n",
       "      <td>for two decades until 2013 north carolina enga...</td>\n",
       "      <td>the new york times</td>\n",
       "      <td>news</td>\n",
       "      <td>httpswwwnytimescom20170331sportsncaabasketball...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  abstract                 articleID articleWordCount  \\\n",
       "0      nan  58def1347c459f24986d7c80              716   \n",
       "1      nan  58def3237c459f24986d7c84              823   \n",
       "2      nan  58def9f57c459f24986d7c90              575   \n",
       "3      nan  58defd317c459f24986d7c95             1374   \n",
       "\n",
       "                                byline documentType  \\\n",
       "0  by stephen hiltner and susan lehman      article   \n",
       "1                      by gail collins      article   \n",
       "2               by the editorial board      article   \n",
       "3                    by michael powell      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  finding an expansive view  of a forgotten peop...   \n",
       "1                   and now  the dreaded trump curse   \n",
       "2               venezuelas descent into dictatorship   \n",
       "3              stain permeates basketball blue blood   \n",
       "\n",
       "                                            keywords multimedia    newDesk  \\\n",
       "0  photography new york times niger ferguson adam...          3    insider   \n",
       "1  united states politics and government trump do...          3       oped   \n",
       "2   venezuela politics and government maduro nicolas          3  editorial   \n",
       "3  basketball college university of north carolin...          3     sports   \n",
       "\n",
       "  printPage          pubDate         sectionName  \\\n",
       "0         2  20170401 001541             unknown   \n",
       "1        23  20170401 002358             unknown   \n",
       "2        22  20170401 005306             unknown   \n",
       "3         1  20170401 010652  college basketball   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  one of the largest photo displays in times his...  the new york times   \n",
       "1                   meet the gang from under the bus  the new york times   \n",
       "2  a court ruling annulling the legislatures auth...  the new york times   \n",
       "3  for two decades until 2013 north carolina enga...  the new york times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           news  httpswwwnytimescom20170331insidernigermigrants...  \n",
       "1           oped  httpswwwnytimescom20170331opinionandnowthedrea...  \n",
       "2      editorial  httpswwwnytimescom20170331opinionvenezuelasdes...  \n",
       "3           news  httpswwwnytimescom20170331sportsncaabasketball...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize = 4\n",
    "train = pd.read_csv(\"/root/Springboard/Data/ArticlesApril2017.csv\", header=0, nrows=sampleSize)\n",
    "#train.head(5)\n",
    "\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "nonstrings = [2, 7, 9]\n",
    "\n",
    "\n",
    "train= train.astype(str)\n",
    "train.fillna(0)\n",
    "\n",
    "def clean_articles(doc):\n",
    "    for index, column in enumerate(doc):\n",
    "        if index in nonstrings:\n",
    "            doc[column] = doc[column].astype(str)\n",
    "            continue\n",
    "        doc[column] = doc[column].str.replace('[^\\w\\s]','')\n",
    "        doc[column] = doc[column].str.lower()\n",
    "        #doc[column] = doc[column].str.strip()\n",
    "        doc[column] = doc[column].replace(np.nan, '', regex=True)\n",
    "        doc[column].apply(nltk.word_tokenize)\n",
    "        doc[column].apply(lemmatize_text)\n",
    "        doc[column] = [token for token in doc[column] if token not in stop_words]\n",
    "    return doc\n",
    "\n",
    "def lemmatize_text(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "#For testing, but this functionality has been compressed into clean_articles\n",
    "def norm_articles(doc):\n",
    "    clean_articles(doc)\n",
    "    doc3 = []\n",
    "    for index, row in doc.iterrows():\n",
    "        element = str(row.to_frame().T)\n",
    "        print(index)\n",
    "        tokenData = nltk.word_tokenize(element)\n",
    "        lemma_tokens = lemmatize_text(tokenData)\n",
    "        #print(tokenData)\n",
    "        #print(\"EFFEW\")\n",
    "        filtered_tokens = [token for token in lemma_tokens if token not in stop_words]\n",
    "        doc2 = ' '.join(filtered_tokens)\n",
    "        doc3.append(doc2)\n",
    "    #print(type(doc3))\n",
    "    return doc3\n",
    "\n",
    "\n",
    "\n",
    "normalize_corpus = np.vectorize(norm_articles)\n",
    "\n",
    "clean_art = clean_articles(train)\n",
    "\n",
    "clean_art.head(5)\n",
    "#pprint(clean_art2)\n",
    "\n",
    "#print('\\n'.join(clean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>Now we want a separate section to clean the comment files. </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approveDate</th>\n",
       "      <th>commentBody</th>\n",
       "      <th>commentID</th>\n",
       "      <th>commentSequence</th>\n",
       "      <th>commentTitle</th>\n",
       "      <th>commentType</th>\n",
       "      <th>createDate</th>\n",
       "      <th>depth</th>\n",
       "      <th>editorsSelection</th>\n",
       "      <th>parentID</th>\n",
       "      <th>...</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userTitle</th>\n",
       "      <th>userURL</th>\n",
       "      <th>inReplyTo</th>\n",
       "      <th>articleID</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>printPage</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1491245186</td>\n",
       "      <td>this project makes me happy to be a 30 year ti...</td>\n",
       "      <td>22022598.0</td>\n",
       "      <td>22022598</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491237056.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>riverside ca</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1491188619</td>\n",
       "      <td>stunning photos and reportage infuriating that...</td>\n",
       "      <td>22017350.0</td>\n",
       "      <td>22017350</td>\n",
       "      <td>nan</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491180489.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>br</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1491188617</td>\n",
       "      <td>brilliant work from conception to execution iv...</td>\n",
       "      <td>22017334.0</td>\n",
       "      <td>22017334</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491179470.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>raleigh nc</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1491167820</td>\n",
       "      <td>nyt reporters should provide a contributors li...</td>\n",
       "      <td>22015913.0</td>\n",
       "      <td>22015913</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491150196.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>missouri usa</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1491167815</td>\n",
       "      <td>could only have been done in print stunning</td>\n",
       "      <td>22015466.0</td>\n",
       "      <td>22015466</td>\n",
       "      <td>&lt;br/&gt;</td>\n",
       "      <td>comment</td>\n",
       "      <td>1491147284.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>tucson arizona</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0</td>\n",
       "      <td>58def1347c459f24986d7c80</td>\n",
       "      <td>unknown</td>\n",
       "      <td>insider</td>\n",
       "      <td>716.0</td>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  approveDate                                        commentBody   commentID  \\\n",
       "0  1491245186  this project makes me happy to be a 30 year ti...  22022598.0   \n",
       "1  1491188619  stunning photos and reportage infuriating that...  22017350.0   \n",
       "2  1491188617  brilliant work from conception to execution iv...  22017334.0   \n",
       "3  1491167820  nyt reporters should provide a contributors li...  22015913.0   \n",
       "4  1491167815       could only have been done in print stunning   22015466.0   \n",
       "\n",
       "  commentSequence commentTitle commentType    createDate depth  \\\n",
       "0        22022598        <br/>     comment  1491237056.0     1   \n",
       "1        22017350          nan     comment  1491180489.0     1   \n",
       "2        22017334        <br/>     comment  1491179470.0     1   \n",
       "3        22015913        <br/>     comment  1491150196.0     1   \n",
       "4        22015466        <br/>     comment  1491147284.0     1   \n",
       "\n",
       "  editorsSelection parentID  ...    userLocation userTitle userURL inReplyTo  \\\n",
       "0            False      0.0  ...    riverside ca       nan     nan         0   \n",
       "1            False      0.0  ...              br       nan     nan         0   \n",
       "2            False      0.0  ...      raleigh nc       nan     nan         0   \n",
       "3            False      0.0  ...    missouri usa       nan     nan         0   \n",
       "4            False      0.0  ...  tucson arizona       nan     nan         0   \n",
       "\n",
       "                  articleID sectionName  newDesk articleWordCount printPage  \\\n",
       "0  58def1347c459f24986d7c80     unknown  insider            716.0         2   \n",
       "1  58def1347c459f24986d7c80     unknown  insider            716.0         2   \n",
       "2  58def1347c459f24986d7c80     unknown  insider            716.0         2   \n",
       "3  58def1347c459f24986d7c80     unknown  insider            716.0         2   \n",
       "4  58def1347c459f24986d7c80     unknown  insider            716.0         2   \n",
       "\n",
       "  typeOfMaterial  \n",
       "0           news  \n",
       "1           news  \n",
       "2           news  \n",
       "3           news  \n",
       "4           news  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For all data - train = pd.read_csv(\"/root/Springboard/Data/cleaning/allComments.csv\")\n",
    "\n",
    "sampleSize = 1000\n",
    "train = pd.read_csv(\"/root/Springboard/Data/CommentsApril2017.csv\", nrows=sampleSize)\n",
    "\n",
    "train= train.astype(str)\n",
    "train.fillna(0)\n",
    "strings = [1, 5, 10, 18, 22, 24, 25, 26, 29, 30, 33]\n",
    "\n",
    "def lemmatize_text(tokenized_text):\n",
    "    text = [wn.lemmatize(word) for word in tokenized_text]\n",
    "    return text\n",
    "\n",
    "def clean_articles(doc):\n",
    "    for index, column in enumerate(doc):\n",
    "        if index in strings:         \n",
    "            doc[column] = doc[column].str.replace('[^\\w\\s]','')\n",
    "            doc[column] = doc[column].str.lower()\n",
    "            #doc[column] = doc[column].str.strip()\n",
    "            doc[column] = doc[column].replace(np.nan, '', regex=True)\n",
    "            doc[column].apply(nltk.word_tokenize)\n",
    "            doc[column].apply(lemmatize_text)\n",
    "            doc[column].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "        else:\n",
    "            doc[column] = doc[column].astype(str)\n",
    "            continue\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(norm_articles)\n",
    "\n",
    "clean_comments = clean_articles(train)\n",
    "#The second command takes awhile to run\n",
    "clean_comments.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_file_name = \"cleaned_article_data.csv\"\n",
    "clean_art_csv = clean_art.to_csv(art_file_name, encoding='utf-8', index=False)\n",
    "\n",
    "com_file_name = \"cleaned_comment_data.csv\"\n",
    "clean_com_csv = clean_comments.to_csv(com_file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
